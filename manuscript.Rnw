\documentclass[a4paper,12pt]{article}
\usepackage[margin=1in]{geometry}
\usepackage[utf8]{inputenc}
%\usepackage{times}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{natbib}
\usepackage{amsmath}
\usepackage{setspace}
\usepackage[normalem]{ulem}
\usepackage{sectsty}
\subsectionfont{\normalfont\large\underline}
\usepackage{floatrow}
\floatsetup[figure]{capposition=top}
\floatsetup[table]{capposition=top}

\title{Measuring Subgroup Preferences in Conjoint Experiments}
\author{Thomas J. Leeper, Sara B. Hobolt, and James Tilley}

\begin{document}

\maketitle

{\abstract Conjoint analysis is an increasingly prominent tool for studying political preferences. The method powerfully disentangles patterns in respondents' favorability toward complex, multidimensional objects, such as political candidates or public policies. Most conjoint analyses rely upon a fully randomized conjoint design to generate average marginal component effects (AMCEs), which measure the degree to which a given value of a conjoint profile feature increases or decreases respondents' support for the overall profile relative to a baseline, averaging across all respondents and all other profile features. While the AMCE has a clear causal interpretation, most published conjoint analyses also use AMCEs to simply describe preferences, often including comparisons of AMCEs between subgroups of respondents. We show how this descriptive use of conditional AMCEs can be substantially misleading about the degree of agreement or disagreement between subgroups due the simple, but often forgotten, property that interactions are sensitive to the reference category used in regression analysis. This leads to inferences about subgroup differences in preferences that have arbitrary sign, size, and significance. We demonstrate the problem using examples drawn from the published literature and provide suggestions for improved reporting and interpretation using two quantities of interest: the marginal mean and the omnibus F-test. Given the rapidly accelerating use of conjoint analyses, this paper makes an important contribution by highlighting pitfalls and presenting advice for best practice in the analysis and presentation of conjoint experiments.}


<<hidden, eval=FALSE, echo=FALSE, results="hide">>=
# setwd("c:/users/thomas/dropbox/brexit identity/papers/subgroupanalysis")
# knitr::knit2pdf("manuscript.Rnw", quiet = TRUE)
@

<<knitr_options, cache=FALSE, echo=FALSE, results="hide">>=
knitr::opts_chunk$set(cache = TRUE, echo=FALSE, results="hold", warning=FALSE, error=FALSE)
options(scipen = 10)
@

<<setup, cache=FALSE>>=
library("rio")
library("cregg")
library("ggplot2")
requireNamespace("xtable", quietly = TRUE)
@

<<data_hainmueller_candidate>>=
# Hainmueller et al. candidate experiment
hainmueller_candidate <- cj_df(rio::import("data/hainmueller-candidate.dta"))

# levels and labels
hainmueller_candidate$atmilitary <- rio::factorize(hainmueller_candidate$atmilitary)
attr(hainmueller_candidate$atmilitary, "label") <- "Military Service"

hainmueller_candidate$atreligion <- rio::factorize(hainmueller_candidate$atreligion)
attr(hainmueller_candidate$atreligion, "label") <- "Religion"

hainmueller_candidate$ated <- rio::factorize(hainmueller_candidate$ated)
attr(hainmueller_candidate$ated, "label") <- "College"

hainmueller_candidate$atprof <- rio::factorize(hainmueller_candidate$atprof)
attr(hainmueller_candidate$atprof, "label") <- "Profession"

hainmueller_candidate$atinc <- rio::factorize(hainmueller_candidate$atinc)
attr(hainmueller_candidate$atinc, "label") <- "Income"

hainmueller_candidate$atrace <- rio::factorize(hainmueller_candidate$atrace)
attr(hainmueller_candidate$atrace, "label") <- "Race/Ethnicity"

hainmueller_candidate$atage <- rio::factorize(hainmueller_candidate$atage)
attr(hainmueller_candidate$atage, "label") <- "Age"

hainmueller_candidate$atmale <- rio::factorize(hainmueller_candidate$atmale)
attr(hainmueller_candidate$atmale, "label") <- "Gender"
@

<<data_hainmueller_immigration>>=
# Hainmueller et al. immigration experiment
hainmueller_immigration <- cj_df(rio::import("data/hainmueller-immigrant.dta"))

## outcome
hainmueller_immigration$ChosenImmigrant <- hainmueller_immigration$Chosen_Immigrant
hainmueller_immigration$Chosen_Immigrant <- NULL

## setup features
hainmueller_immigration$Gender <- rio::factorize(hainmueller_immigration$FeatGender)
attr(hainmueller_immigration$Gender, "label") <- "Gender"
hainmueller_immigration$FeatGender <- NULL

hainmueller_immigration$Education <- rio::factorize(hainmueller_immigration$FeatEd)
levels(hainmueller_immigration$Education) <- sub(" in the US", "", levels(hainmueller_immigration$Education))
attr(hainmueller_immigration$Education, "label") <- "Education"
hainmueller_immigration$FeatEd <- NULL

hainmueller_immigration$LanguageSkills <- rio::factorize(hainmueller_immigration$FeatLang)
levels(hainmueller_immigration$LanguageSkills) <- sub("During( the)? admission interview, this applicant ", "", levels(hainmueller_immigration$LanguageSkills))
attr(hainmueller_immigration$LanguageSkills, "label") <- "Language Skills"
hainmueller_immigration$FeatLang <- NULL

hainmueller_immigration$CountryOfOrigin <- rio::factorize(hainmueller_immigration$FeatCountry)
hainmueller_immigration$CountryOfOrigin <- relevel(hainmueller_immigration$CountryOfOrigin, "India")
attr(hainmueller_immigration$CountryOfOrigin, "label") <- "Country of Origin"
hainmueller_immigration$FeatCountry <- NULL

hainmueller_immigration$Job <- rio::factorize(hainmueller_immigration$FeatJob)
attr(hainmueller_immigration$Job, "label") <- "Job"
hainmueller_immigration$FeatJob <- NULL

hainmueller_immigration$JobExperience <- rio::factorize(hainmueller_immigration$FeatExp)
attr(hainmueller_immigration$JobExperience, "label") <- "Job Experience"
hainmueller_immigration$FeatExp <- NULL

hainmueller_immigration$JobPlans <- rio::factorize(hainmueller_immigration$FeatPlans)
levels(hainmueller_immigration$JobPlans) <- sub(" but has done job interviews", "", levels(hainmueller_immigration$JobPlans))
attr(hainmueller_immigration$JobPlans, "label") <- "Job Plans"
hainmueller_immigration$FeatPlans <- NULL

hainmueller_immigration$ReasonForApplication <- rio::factorize(hainmueller_immigration$FeatReason)
attr(hainmueller_immigration$ReasonForApplication, "label") <- "Reason for Application"
hainmueller_immigration$FeatReason <- NULL

hainmueller_immigration$PriorEntry <- rio::factorize(hainmueller_immigration$FeatTrips)
attr(hainmueller_immigration$PriorEntry, "label") <- "Prior Entry"
hainmueller_immigration$FeatTrips <- NULL

## covariates
hainmueller_immigration$ethnocentrism_split <- ifelse(is.na(hainmueller_immigration$ethnocentrism), NA_real_, ifelse(hainmueller_immigration$ethnocentrism > 10, 1, 0))
hainmueller_immigration$ethnocentrism_split <- factor(hainmueller_immigration$ethnocentrism_split, levels = c(0,1), labels = c("low", "high"))
@

<<data_bms>>=
if (file.exists("data/bms.rds")) {
    bms <- cj_df(rio::import("data/bms.rds"))
} else {
    bms <- cj_df(rio::import("data/ballard-rosa.dta"))
    
    # setup terms
    bms$taxrate1 <- factor(rio::characterize(bms$taxrate1),
                           levels = c("0%", "5%", "15%", "25%"),
                           labels = c("<10k: 0%", "<10k: 5%", "<10k: 15%", "<10k: 25%"))
    bms$taxrate2 <- factor(rio::characterize(bms$taxrate2),
                           levels = c("5%", "15%", "25%", "35%"),
                           labels = c("10-35k: 5%", "10-35k: 15%", "10-35k: 25%", "10-35k: 35%"))
    bms$taxrate3 <- factor(rio::characterize(bms$taxrate3),
                           levels = c("5%", "15%", "25%", "35%"),
                           labels = c("35-85k: 5%", "35-85k: 15%", "35-85k: 25%", "35-85k: 35%"))
    bms$taxrate4 <- factor(rio::characterize(bms$taxrate4),
                           levels = c("5%", "15%", "25%", "35%"),
                           labels = c("85-175k: 5%", "85-175k: 15%", "85-175k: 25%", "85-175k: 35%"))
    bms$taxrate5 <- factor(rio::characterize(bms$taxrate5),
                           levels = c("5%", "15%", "25%", "35%", "45%"),
                           labels = c("175-375k: 5%", "175-375k: 15%", "175-375k: 25%", "175-375k: 35%", "175-375k: 45%"))
    bms$taxrate6 <- factor(rio::characterize(bms$taxrate6),
                           levels = c("5%", "15%", "25%", "35%", "45%", "55%"),
                           labels = c(">375k: 5%", ">375k: 15%", ">375k: 25%", ">375k: 35%", ">375k: 45%", ">375k: 55%"))
    bms$taxrev <- factor(rio::characterize(bms$taxrev),
                         levels = rev(c("Much more revenue (>125%)",
                                        "More revenue (105-125%)",
                                        "About the same revenue (95-105%)",
                                        "Less revenue (75-95%)",
                                        "Much less revenue (<75%)")),
                         labels = c("<75%", "75-95%", "95-105%", "105-125%", ">125%"))
    
    # subset variables
    bms <- bms[c("chose_plan", "taxrate1", "taxrate2", "taxrate3", "taxrate4", "taxrate5", "taxrate6", "taxrev",
                 "ineq_averse_dum", "hh_income", "taxes_harm_econ", "work_vs_luck", "race", "above_avg_racial_resentment",
                 "repub_7pt", "democ_7pt", "indep_7pt", "ID", "weight", "saw_revenue")]

    # subset (according to original do file)
    bms <- bms[bms$saw_revenue == 1,]
    
    # label
    attr(bms$taxrate1, "label") <- "Tax rate for <$10,000"
    attr(bms$taxrate2, "label") <- "Tax rate for $10,000-$35,000"
    attr(bms$taxrate3, "label") <- "Tax rate for $25,000-$85,000"
    attr(bms$taxrate4, "label") <- "Tax rate for $85,000-$175,000"
    attr(bms$taxrate5, "label") <- "Tax rate for $175,000-$375,000"
    attr(bms$taxrate6, "label") <- "Tax rate for >$375,000"
    attr(bms$taxrev, "label") <- "Tax revenue"

    # export
    rio::export(bms, "data/bms.rds")
}
bms$taxes_harm_split <- factor(ifelse(bms$taxes_harm_econ == 1, "Help", ifelse(bms$taxes_harm_econ == 2, "Harm", NA)))
@


<<data_tkr>>=
if (file.exists("data/tkr.rds")) {
    tkr <- cj_df(rio::import("data/tkr.rds"))
} else {
    # load original data file
    tkr <- cj_df(rio::import("data/teele.dta"))
    
    # recode respondent characteristics
    tkr[["sample"]] <- c("usa voter" = "Voter", "usa leg" = "Legislator")[tkr[["sample"]]]
    
    # subset to voters
    tkr <- tkr[tkr[["sample"]] == "Voter", ]
    
    tkr[["Sex"]] <- factor(c("Male", "Female")[tkr[["female_respondent"]]+1L])
    
    tkr[["PartyID"]] <- NA_integer_
    tkr[["PartyID"]][tkr[["democrat_respondent"]] == 1] <- "Democrat"
    tkr[["PartyID"]][tkr[["republican_respondent"]] == 1] <- "Republican"
    tkr[["PartyID"]] <- factor(tkr[["PartyID"]])
    
    # label features and feature levels
    ## Sex
    tkr[["feature_sex"]] <- factor(tkr[["orig_cand_female"]], c(0,1), c("Male", "Female"))
    attr(tkr[["feature_sex"]], "label") <- "Candidate Sex"
    
    ## Political experience
    tkr[["feature_experience"]] <- NA_integer_
    tkr[["feature_experience"]][tkr[["orig_0ys"]] == 1] <- 1L
    tkr[["feature_experience"]][tkr[["orig_1ys"]] == 1] <- 2L
    tkr[["feature_experience"]][tkr[["orig_3ys"]] == 1] <- 3L
    tkr[["feature_experience"]][tkr[["orig_8ys"]] == 1] <- 4L
    tkr[["feature_experience"]] <- factor(tkr[["feature_experience"]], 1:4, c("None", "1 year", "3 years", "8 years"))
    attr(tkr[["feature_experience"]], "label") <- "Political Experience"
    
    ## Martial status
    tkr[["feature_marital"]] <- NA_integer_
    tkr[["feature_marital"]][tkr[["orig_UN_sp"]] == 1] <- 1L
    tkr[["feature_marital"]][tkr[["orig_FM_sp"]] == 1] <- 2L
    tkr[["feature_marital"]][tkr[["orig_MD_sp"]] == 1] <- 3L
    tkr[["feature_marital"]] <- factor(tkr[["feature_marital"]], 1:3, c("Unmarried", "Doctor Spouse", "Farmer Spouse"))
    attr(tkr[["feature_marital"]], "label") <- "Martial Status"
    
    ## Profession
    tkr[["feature_job"]] <- NA_integer_
    tkr[["feature_job"]][tkr[["orig_teach"]] == 1] <- 1L
    tkr[["feature_job"]][tkr[["orig_law"]] == 1] <- 2L
    tkr[["feature_job"]][tkr[["orig_may"]] == 1] <- 3L
    tkr[["feature_job"]][tkr[["orig_leg"]] == 1] <- 4L
    tkr[["feature_job"]] <- factor(tkr[["feature_job"]], 1:4, c("Teacher", "Corporate Lawyer", "Mayor", "State Legislator"))
    attr(tkr[["feature_job"]], "label") <- "Job"
        
    ## Children
    tkr[["feature_children"]] <- NA_integer_
    tkr[["feature_children"]][tkr[["orig_0ch"]] == 1] <- 1L
    tkr[["feature_children"]][tkr[["orig_1ch"]] == 1] <- 2L
    tkr[["feature_children"]][tkr[["orig_3ch"]] == 1] <- 3L
    tkr[["feature_children"]] <- factor(tkr[["feature_children"]], 1:3, c("No children", "1 child", "3 children"))
    attr(tkr[["feature_children"]], "label") <- "Children"
    
    ## Age
    tkr[["feature_age"]] <- NA_integer_
    tkr[["feature_age"]][tkr[["orig_29"]] == 1] <- 1L
    tkr[["feature_age"]][tkr[["orig_45"]] == 1] <- 2L
    tkr[["feature_age"]][tkr[["orig_65"]] == 1] <- 3L
    tkr[["feature_age"]] <- factor(tkr[["feature_age"]], 1:3, c("29", "45", "65"))
    attr(tkr[["feature_age"]], "label") <- "Age"
    
    ## Office (experimental factor not reported in paper?)
    tkr[["feature_office"]] <- rio::factorize(tkr[["dv"]])
    attr(tkr[["feature_office"]], "label") <- "Office"
        
    # export
    rio::export(tkr, "data/tkr.rds")
}
@

\clearpage


Amidst the dramatically increased use of experiments within political science \citep{Druckmanetal2006, Mutz2011}, conjoint experimental designs have recently become a prominent methodological tool in political science. While traditional survey experiments tend to examine just one or two factors that might shape outcomes \citep[see, for reviews,][]{GainesKuklinskiQuirk2007, Sniderman2011}, conjoint designs allow researchers to study the independent effects on preferences of many features of complex, multidimensional objects such as political candidates \citep{Campbelletal2016, TeeleKallaRosenbluth2018}, immigrant admissions \citep{HainmuellerHopkins2015, BansakHainmuellerHangartner2016, WrightLevyCitrin2016}, or public policies \citep{GallegoMarx2017, Hankinson2018}. The driving force behind this use of conjoint analysis has been the introduction by \citet{HainmuellerHopkinsYamamoto2014} of a fully randomized conjoint design and an associated analytic approach that emphasizes a single quantity of interest: namely, the average marginal component effect (AMCE). By capturing the multidimensionality of target objects, the randomized conjoint design breaks any explicit or implicit confounding between features of these objects, giving the AMCE a clear causal interpretation: the degree to which a given value of a feature increases or decreases respondents' favorability toward a packaged conjoint profile relative to a baseline, averaging across all respondents and all other profile features. 

While randomization of profile features gives the AMCE a causal interpretation, most published conjoint analyses in political science use AMCEs for \textit{descriptive} purposes: that is, to map variation in favorability toward a multidimensional object across its various features. This is particularly the case when researchers engage in subgroup analyses of conjoint experiments in search of preference heterogeneity. For example, \citet{HainmuellerHopkinsYamamoto2014} perform a subgroup analysis on their original immigration experiment in which they perform a median split on a measure of ethnocentrism and then compare AMCEs for the two subgroups. Similarly, \citet{BansakHainmuellerHangartner2016} compare preferences toward immigrants across number of binary respondent characteristics: age, education, left-right ideology, and income. In a different domain, \citet{BallardRosaMartinScheve2016} compare preferences over tax policies across a number of subgroups defined by demographics and political orientations. \citet{TeeleKallaRosenbluth2018} compare AMCEs for features of male and female political candidates among male and female respondents. \citet{KirklandCoppock2017} do a similar comparison between Democrats and Republicans in hypothetical elections.

In these and many other articles, interpretation of these subgroup analyses focus not just on the \textit{causal effects} of profile features within each subgroup (what Hainmueller et al. term ``conditional AMCEs''; 13) but also on an implied quantity of interest: the \textit{difference} between two conditional AMCEs across subgroups. Searching for causal effect heterogeneity is an increasingly common feature of experimental analysis \citep{GreenKern2012, RatkovicTingley2017, GrimmerMessingWestwood2017}, yet most conjoint analyses use this difference-in-AMCEs instead to \textit{descriptively} interpret apparent differences in favorability toward objects with a given feature (e.g., immigrants from Syria) between the two groups (e.g., low and high ethnocentrism respondents).

What is not necessarily obvious in such analyses is that differences-in-preferences (that is to say, the difference in degree of favorability toward profiles containing a given feature) are not directly reflected in differences-in-AMCEs. Yet authors frequently use visual or more formal comparisons of conditional AMCEs to make descriptive claims about such differences, leading themselves and readers astray. Differences in AMCEs do not provide inference into difference between subgroups' favorability toward a conjoint feature. In this paper, we show that a difference in underlying subgroup preferences --- like a difference in willingness to support a Syrian immigrant between high and low ethnocentrism respondents --- is only reflected in the difference-in-AMCEs under particular preference configurations and analytic choices. The underlying cause of this error is simple and familiar to any applied researcher but appears to be forgotten in most applied conjoint work.

As we will show, where preferences in subgroups toward the experimental reference category are similar, the difference-in-AMCEs conveys preferences reasonably well but where preferences between subgroups diverge in the reference category, the difference-in-AMCEs is a misleading representation of underlying patterns of favorability. Yet most published conjoint studies appear to report results based upon reference categories chosen for \textit{substantive} reasons about the nature or meaning of the levels rather than the configuration of preferences revealed in the experiment. Ultimately AMCEs are relative, not absolute, statements about preferences so subgroup differences are also relative not absolute statements about preference heterogeneity.\footnote{For example, in a comparison of subgroup effects for Democrats and Republicans, Republicans might display a smaller effect because their preferences in the reference category are already very positive, such that a large positive effect for Democrats occurs despite Democrats being less supportive than Republicans in either experimental condition.} There is simply no predictable inference to be drawn from subgroup causal effects to the levels of underlying subgroup opinion. This inferential error --- interpreting differences in the size of causal effects as descriptive differences in preferences --- appears to be widespread in published conjoint analyses. The root of this error is likely familiar to many researchers: it is simply a matter of regression specification for models involving interactions between categorical regressors. \citet{EgamiImai2018}, for example, provide an extensive discussion of the implications of this property for interpreting causal interactions between features of conjoint profiles. The state of the published literature would suggest the problem remains non-obvious when applied to descriptive analysis of subgroups in conjoint designs.

In what follows, we demonstrate the challenges of conjoint analysis and reminder readers of how reference category choice for profile features creates significant problems for comparing conditional AMCEs across respondent subgroups. We show how the use of an arbitrary reference category means the size and the direction of differences-in-AMCEs have little relationship to the underlying degree of favorability of the subgroups toward profiles with particular features and that reference category choices can make similar preferences look dissimilar and dissimilar preferences look similar, using examples drawn from the published political science literature (namely experiments by \citealt{HainmuellerHopkinsYamamoto2014, BallardRosaMartinScheve2016, TeeleKallaRosenbluth2018}). The paper then provides suggestions for improved conjoint reporting and interpretation based around two quantities of interest drawn from the factorial experimentation literature: (1) unadjusted marginal means, a quantity measuring favorability toward a given feature, and (b) an omnibus F-test, measuring differences therein. Newly developed software for the R programming language to support our findings --- and that can be used to examine sensitivity of conjoint analysis to reference category selection, calculate AMCEs and marginal means, perform subgroup analyses, and test for subgroup differences in any conjoint experiment --- is demonstrated throughout. We conclude with advice for best practices in the analysis and presentation of conjoint results.

\section*{Quantities of Interest in Conjoint Experiments}\label{sec:quantities}

Conjoint analysis serves two purposes. One is to assess causal effects. Another is preference description.\footnote{Here we use ``preference'' as \citet{HainmuellerHopkinsYamamoto2014} do: that is, as a statement of \textit{favorability} or \textit{support} for a profile, not the more narrow economic definition of a strict rank ordering of objects by favorability.} In causal inference, conjoints provide a design and analytic approach that allows researchers to understand the causal effect of a given feature on overall support for a multidimensional object, averaging across other features of the object included in the design. Such inferences can be thought of as statements of the form: ``shifting an immigrant's country of origin from India to Poland increases favorability by X percentage points.'' In descriptive inference, conjoints provide information about both (a) the \textit{absolute} favorability of respondents toward objects with particular features or combinations of features, and (b) the \textit{relative} favorability of respondents toward an object with alternative combinations of features. Such inferences can be thought of as statements of the form ``Polish immigrants are preferred by X\% of respondents'' or ``Polish immigrants are more supported than Mexican immigrants, by X percentage points.'' Thus both causal and descriptive interpretations of conjoints are based upon the distribution of preferences across profile features and differences in preferences across alternative feature combinations.

Importantly, a fully randomized conjoint design without constraints between profile features is simply a full-factorial experiment (with some cells possibly, albeit randomly, left unobserved). All quantities of interest relevant to the analysis of conjoint designs derive from combinations of cell means, marginal means, and the grand mean, as is common in the traditional analysis of factorial experiments. In a forced choice design, the \textit{grand mean} is by definition 0.5 (i.e., 50\% of all profiles shown are chosen and 50\% are not chosen). \textit{Cell means} are the mean outcome for each particular combination of feature levels. In the full-factorial design discussed by \citet{HainmuellerHopkinsYamamoto2014} and now widely used in political science, many or perhaps most cell means are unobserved. For example, in their candidate choice experiment, there are $2*6*6*6*2*6*6*6 = 186,624$ cell means but only 3,466 observations so about 98\% of cell means are unobserved. While this would be problematic for attempting to infer pairwise comparisons between cells, conjoint analysts mostly focus on the marginal effects of each feature rather than more complex interactions. Appendix \ref{app:quantities} provides detailed notation and elaborations of these definitions of quantities of interest.

Average marginal component effects (AMCEs) depend only upon \textit{marginal means}: that is the column and row mean outcomes for each feature level averaging across all other features. A marginal mean describes the level of favorability toward profiles that have a particular feature level, marginalizing across all other features. For example, in the common forced-choice design with two alternatives, marginal means have a direct interpretation as probabilities: a marginal mean of 0 indicates respondents select profiles with that feature level with probability $Pr(Y=1|X=x) = 0$ while a marginal mean of 1 indicates respondents select profiles with that feature level with probability $(Pr(Y=1|X=x)=1$.\footnote{It is not possible for the marginal mean to equal zero or one if pairs of profiles shown together are allowed to have the same level of a given feature (for example, both immigrants are from Germany). Instead, the marginal mean can range from the probability of co-occurrence to 1 minus that probability. If there are five levels of a feature, each shown with equal probability, then the probability of co-occurrence is $\frac{1}{5}*\frac{1}{5} = 0.04$ such that the marginal mean can take values in the range $(0.04,0.96)$. If the design is constrained so that features cannot be the same for both immigrants, then the marginal means fully range from zero to one. This constraint on the range of the marginal means also constrains the range of AMCEs. Notably, many conjoints provide features with only two levels, such as the male-versus-female candidate feature examined by \citet{TeeleKallaRosenbluth2018}. In such cases, the probability of co-occurrence is $\frac{1}{2}*\frac{1}{2} = 0.25$ bounding the AMCE for female (as opposed to male) candidates to the range $(-0.5, 0.5)$ if both candidates can have the same sex. Caution is therefore needed in comparing the relative size of features with few levels to features with many levels given that effects have different bounds.} With rating scale outcomes, marginal means can vary arbitrarily along the outcome scale used.

<<hainmueller_candidate_replication, dependson=c("data_hainmueller_candidate"), fig.height=6, fig.width=8, fig.cap="Replication of Hainmueller et al. (2014) Candidate Experiment using AMCEs and MMs", fig.show="hold", message=FALSE>>=
plot(
  cregg::cj(
   hainmueller_candidate, 
   selected ~ atmilitary + atreligion + ated + atprof + atinc + atrace + atage + atmale,
   id = ~ resID,
   estimate = "amce"
  ), vline = 0, xlim = c(-0.4,0.4)
)
plot(
  cregg::cj(
   hainmueller_candidate, 
   selected ~ atmilitary + atreligion + ated + atprof + atinc + atrace + atage + atmale,
   id = ~ resID,
   estimate = "mm"
  ), vline = 0.5, xlim = c(0.25,0.75)
)
@

Because levels of features are randomly assigned, pairwise differences between two marginal means for a given feature (e.g., between candidates who are male versus female) have a direct causal interpretation. For fully randomized designs, the AMCE proposed by \citet{HainmuellerHopkinsYamamoto2014} is equivalent to the average marginal effect of each feature level for a model where each feature is converted into a matrix of indicator variables with one level left out as a reference category. This is no different from any other regression context wherein one level of any categorical variable must be omitted from the design matrix in order to avoid perfect multicollinearity.\footnote{In designs that entail constraints between profile features, the average marginal effect is a weighted average of effects across each combination of the constrained features where the weights on the effects are arbitrary but typically uniform. We ignore this distinction in the remainder of this article, as all of our results apply equally to fully randomized and to constrained designs.} This close relationship between AMCEs and marginal means is visible in Figure \ref{fig:hainmueller_candidate_replication} which presents a replication of the AMCE-based analysis of the Hainmueller et al. candidate experiment (upper panel) and an analogous examination of the results using marginal means (lower panel). Here and throughout we use visual presentation of results, but full numerical estimates including appropriate standard errors are presented in the Appendix. Note, in particular, how marginal means convey information about the preferences of respondents for all feature levels while AMCEs definitionally restrict the AMCE for the reference category to zero (or undefined). For example, the AMCE for a candidate serving in the military is 0.09 (or a 9-percentage point) increase in favorability, reflecting marginal means for serving and non-serving candidates of 0.46 and 0.54, respectively.

The AMCE is often described as an estimate of the relative favorability of profiles with counterfactual levels of a feature; for example, ``male candidates are preferred to female candidates'' \citep[6]{TeeleKallaRosenbluth2018}. \citet{HainmuellerHopkinsYamamoto2014} similarly describe some of the results of conjoint on preferences toward Congressional candidates:

\begin{quote}
We also see a bias against Mormon candidates, whose estimated level of support is 0.06 (SE = 0.03) lower when compared to a baseline candidate with no stated religion. Support for Evangelical Protestants is also 0.04 percentage points lower (SE = 0.02) than the baseline. (19)
\end{quote}

\noindent These examples make clear that despite the \textit{causal} inference potentially provided by the AMCE, the quantity of interest is frequently used to provide a characterization of a preferences that has a distinctly descriptive flavor. Indeed, this style of description is widespread in conjoint analyses. \citet{BallardRosaMartinScheve2016} interpretation their tax preference conjoint:

\begin{quote}
we find strong support for progressive preferences over federal income taxes among the American public [\dots] respondents are less likely to support a given tax plan as the tax rate on the poorest three groups increases but more likely to support an income tax policy when the tax rate on the richest two groups increases, at least to a point.
\end{quote}

\noindent This use of conjoints to provide descriptive inferences about patterns of preferences is important because AMCEs are defined as \textit{relative} quantities, requiring that patterns of preferences are expressed against a baseline, reference category for each conjoint feature. A positive (negative) AMCE is read as higher (lower) favorability but it is only higher (lower) relative to whatever category serves as the baseline. For example, in the \citeauthor{HainmuellerHopkinsYamamoto2014} candidate example, choosing a non-religious candidate as a baseline means the AMCEs in the candidate experiment are all expressed relative to this non-religious baseline; the difference (if any) between other pairs of marginal means (e.g., evaluations of Mormon and Evangelical candidates) is not obvious. Relatedly, the negative direction (and the size) of the AMCEs for Mormon and Evangelical candidates would be different if the least-liked category (Mormon candidates) were the reference group. In that case, the AMCE for Evangelicals would be small and positive and the AMCEs for all other categories (including the presented reference category, ``none'') would be large and positive.

<<reference_category, dependson=c("data_hainmueller_immigration"), fig.width=8, fig.height=5, fig.cap="Reference Category Diagnostic for the 'Education' Feature from Hainmueller et al.'s (2014) Immigration Experiment">>=
tmp <- amce_by_reference(hainmueller_immigration, ChosenImmigrant ~ Education, ~ Education, id = ~CaseID)
ggplot(tmp, aes(x = estimate, y = level, group = BY, colour = BY)) +
  geom_vline(xintercept = 0, colour = "gray") +
  geom_point(position = ggstance::position_dodgev(height = 0.5)) +
  geom_errorbarh(aes(xmin = lower, xmax = upper),  
                 size = 0.2, height = 0,
                 position = ggstance::position_dodgev(height = 0.5)) + 
  scale_colour_discrete(guide = ggplot2::guide_legend(title = "Reference Category", ncol = 1)) +
  scale_x_continuous(limits = c(-.3,.3), oob = scales::rescale_none) +
  ylab("") +
  xlab("Estimated AMCE") + 
  theme_minimal() + 
      ggplot2::theme(
        legend.position = "bottom",
        panel.grid.major = ggplot2::element_blank(),
        panel.grid.minor = ggplot2::element_blank()
      )
rm(tmp)
@

Being a familiar analytic problem in any regression context, this choice of reference category for estimating AMCEs can seem trivial but is quite consequential. For example, in \citeauthor{HainmuellerHopkinsYamamoto2014}'s candidate experiment, the least liked education level (``no formal education'') is chosen as a reference category, but the authors could have presented the results using any of the categories as the baseline. Figure \ref{fig:reference_category} shows how the estimated AMCEs for each level of education would have differed depending on that choice. Selecting a reference category that receives middling support (i.e., more favorability than some other feature levels but less favorability than others), makes some AMCEs positive and others negative but all AMCEs can be made positive (or negative) simply by choosing a different baseline.\footnote{As another example, in \citeauthor{BallardRosaMartinScheve2016}'s tax preference experiment, the lowest level of taxation is chosen as the reference category for each feature for reasons of substantive interpretation, yet despite the substantive intuitiveness of this, favorability toward the lowest level of taxation is not necessarily higher or lower than preferences for alternative tax rates.} The results would be numerically equivalent --- the alternative linear models used to the estimate the AMCEs have a mathematical equivalence --- but the choice has sizeable consequences for the interpretation of conjoint analyses, as we discuss below.\footnote{In \textit{constrained} conjoint designs, the choice of reference category is even more important. Consider, for example, the design of \citeauthor{HainmuellerHopkinsYamamoto2014}'s immigration experiment, which constrains the ``Country of Origin`` feature so that levels `India,' `Germany,' `France,' `Mexico,' `Philippines,' and `Poland' cannot co-occur with the `Escape Persecution' level of the ``Reason for Application'' feature. Consequently, the AMCE for the ``Escape Persecution'' level (relative to the  ``Reunite with family'' reference category) is only defined for the subset of the design involving countries `China,' `Sudan,' `Somalia,' and `Iraq.' The AMCEs for those four countries (relative to India as a baseline) marginalize across all reasons for application, but the AMCEs for the first six countries marginalize only across the latter two reasons. Thus the interpretation of AMCEs --- and the basic ability to estimate them in constrained designs --- depends entirely upon the selection of a reference category where all feature levels can co-occur. In a design where \textit{all} features are constrained, then AMCEs are undefined for the design as a whole and only estimable for subsets of the design that are \textit{conditionally} unconstrained.}

%To demonstrate this, Figure \ref{fig:reference_category} shows the estimated AMCEs for the country of origin feature from \citeauthor{HainmuellerHopkinsYamamoto2014}'s immigration experiment, with the analysis repeated ten times each time using a different country as the reference category. For example, the top-most set of points and error bars convey the AMCE for Iraq from each of these analyses. When Iraq is the reference category, its AMCE is undefined. When any other country is chosen as a reference category, the AMCE for Iraq is negative because respondents are more negative toward Iraqi immigrants than they are toward those of other countries. Similarly, the bottom set of points and error bars reflects the estimated AMCEs for Germany. When Germany is the reference category, its AMCE is undefined but when any other country is used as the reference category, its AMCE is positive.

%These cases are therefore not \textit{directionally} sensitive to the choice of reference category but of course the point estimates vary considerably. But the estimated AMCE of countries who are neither strongly disliked or strongly favored by respondents are highly sensitive to choice of reference category. Consider, for example, the estimated AMCEs for China (the four set of points from the top). When highly disliked countries are chosen as the reference category (like Somalia, Sudan, or Iraq), the AMCE for China is positive; when highly favored countries are chosen (like Germany, Poland, or the Philippines), the AMCE for China is negative.

\section*{Consequences of Arbitrary Reference Category Choice}\label{sec:challenges}

Given the need to choose a reference category for every feature in order to estimate AMCEs, an important question is: how do researchers decide which of tens of thousands of possible experimental cells should be selected as the reference category? Examining recently published conjoint analyses, it appears that the choice of reference category is either arbitrary or based upon substantive intuition about the meaning of feature levels. For example, \citet{HainmuellerHopkinsYamamoto2014} choose female immigrants as a baseline in their immigration experiment, thus providing an estimate of the AMCE of being male, while \citet{TeeleKallaRosenbluth2018} choose male candidates as a baseline in their conjoint, thus providing an estimate of the AMCE of being female. The choice is seemingly innocuous. Sometimes choices of reference category appear to be driven by substantive knowledge: on language skills of immigrants, \citet{HainmuellerHopkinsYamamoto2014} choose fluency as a baseline; on the prior trips to the US feature, ``never'' is chosen as the baseline. These seem sensible on face value --- it might seem less useful to define all effects relative to ``having visited many times as a tourist'' as the AMCEs then lose an immediately intuitive interpretation.

% Difference in conditional AMCEs
\begin{table}
\caption{Uses of Subgroup Analysis Published in Political Science Journals}\label{tab:papers}
\begin{center}
\footnotesize
\begin{tabular}{p{2in} p{2in} p{2in}}\toprule
\textbf{Paper} & \textbf{Topic} & \textbf{Subgroup Comparisons} \\ \midrule
\citet{BechtelScheve2013} & Climate agreement preferences & Environmentalism and International Reciprocity Attitudes \\ \midrule
\citet{FranchinoZucchini2014} & Candidate preferences & Political Interest, Left-right self-placement\\ \midrule
\citet{HainmuellerHopkinsYamamoto2014} & Immigration preferences & Ethnocentrism \\ \midrule
\citet{HansenOlsenBech2014} & Policy preferences & Partisanship \\ \midrule
\citet{Carlson2015} & Candidate preferences & Co-ethnicity \\ \midrule
\citet{BansakHainmuellerHangartner2016} & Immigration preferences & Left-right self-placement, age, education, income\\ \midrule
\citet{BallardRosaMartinScheve2016} & Tax preferences & Various\\ \midrule
\citet{Campbelletal2016} & Candidate preferences & Partisanship \\ \midrule
\citet{CarnesLupu2016} & Candidate preferences & Partisanship \\ \midrule
\citet{Mummolo2016} & News selection & Various\\ \midrule
\citet{VivyanWagner2016} & Candidate preferences & Political attitudes \\ \midrule
\citet{MummoloNall2017} & Mobility preferences & Partisanship \\ \midrule
\citet{BechtelGenoveseScheve2017} & Climate agreement preferences & Employment sector emissions \\ \midrule
\citet{BechtelHainmuellerMargalit2017} & International bailout preferences & Various\\ \midrule
\citet{GallegoMarx2017} & Labor market policy & Left-right self-placement \\ \midrule
\citet{KirklandCoppock2017} & Candidate preferences & Partisanship \\ \midrule
\citet{Sen2017} & Judicial candidate preferences & Partisanship \\ \midrule
\citet{Sobolewskaetal2017} & Immigrant integration & Various \\ \midrule
\citet{EggersVivyanWagner2018} & Candidate preferences & Sex \\ \midrule
\citet{Hankinson2018} & Housing policy preferences & Various \\ \midrule
\citet{OliverosSchuster2018} & Bureaucrat candidate preferences & Various \\ \midrule
\citet{TeeleKallaRosenbluth2018} & Candidate preferences & Sex, Partisanship \\ \midrule
\citet{Careyetal2018} & Hiring preferences & Various \\ \midrule
\bottomrule
\end{tabular}
\end{center}
All articles in this table use subgroup conditional AMCEs to make inferences about differences in preferences between subgroups.
\end{table}

Yet the choice is consequential. A possibly surprising consequence of the seemingly arbitrary selection of a reference category --- and the resulting arbitrariness of both the size and direction of AMCEs --- is that it can provide highly distorted descriptive interpretation of preferences among subgroups of respondents. This occurs when researchers examine \textit{conditional} AMCEs, wherein AMCEs are calculated separately for subgroups of respondents and those conditional estimates are directly compared \citep[13]{HainmuellerHopkinsYamamoto2014}. Table \ref{tab:papers} reports a list of recently published articles in political science that engage in this form of subgroup analysis.\footnote{\citet{RatkovicTingley2017} considered efficient methods for performing subgroup analyses in conjoint designs. Our focus here is on the narrower problem of interpreting subgroup analyses as traditionally performed using subsetting or interaction terms in a regression framework.} Given the commonly descriptive interpretations of conjoint experimental results, such subgroup analyses seem perfectly intuitive and the set of subgroups listed in the last column of Table \ref{tab:papers} contains some unsurprising covariates, such as partisanship, that are of obvious theoretical interest in almost any study of individual preferences. Analytically, these conditional AMCEs can be obtained either from regression estimates on respondent subgroups or through interactions between conjoint features and respondent characteristics, the details of which are unimportant for our purposes.

Conditional AMCEs are not per se a problematic quantity of inference. Like subgroup analysis of any experiment, they convey the causal effect of an experimental factor on overall favorability among the subgroup of interest. Consider, for example, a two-condition party cue experiment where Democrats and Republicans are exposed to an endorsement cue from the Democratic party or no cue and opinions toward the policy serve as the outcome. It is sensible to imagine that effects of the cue might differ for the two groups and therefore to compare the size of cue effect among the two groups. Perhaps Democrats are more responsive to the Democratic party cue than are Republicans, making the causal effect larger for Democrats than Republicans. Discussions of conditional AMCEs in conjoint analyses often explicitly or implicitly engage in this kind of discussion comparing the size and direction of subgroup causal effects. If interpreted as a difference in the size of the causal effect for two groups, such comparisons are perfectly consistent with more traditional experimental analysis and a perfectly acceptable interpretation of the conjoint results.

<<tkr_replication, dependson=c("data_tkr"), fig.height=5, fig.width=8, fig.cap="Replication of Teele et al. (2018) Candidate Experiment using AMCEs and MMs", fig.show="hold", message=FALSE>>=
plot(
  cj(
   tkr, 
   winner ~ feature_sex + feature_experience + feature_marital + feature_job + feature_children + feature_age,
   id = ~ responseid,
   estimate = "amce",
   by = ~ PartyID
  ), vline = 0, group = "PartyID", xlim = c(-0.35, 0.35)
) + scale_colour_manual("PartyID", limits = c("Democrat", "Republican"), values = c("Blue", "Red"))
plot(
  cj(
   tkr, 
   winner ~ feature_sex + feature_experience + feature_marital + feature_job + feature_children + feature_age,
   id = ~ responseid,
   estimate = "mm",
   by = ~ PartyID
  ), vline = 0.5, group = "PartyID", xlim = c(0.3,0.7)
) + scale_colour_manual("PartyID", limits = c("Democrat", "Republican"), values = c("Blue", "Red"))
@

Yet, just as analysis of full sample conjoint data is often descriptive in nature, so too do conjoint analysts frequently interpret differences in conditional AMCEs descriptively rather than causally. For example, in one analysis \citet{HainmuellerHopkinsYamamoto2014} visually compare the pattern of AMCEs among high- and low-ethnocentrism respondents and interpret that ``the patterns of support are generally similar for respondents irrespective of their level of ethnocentrism'' (22). \citet{BallardRosaMartinScheve2016} make similar comparisons in their tax policy conjoint: ``While there are few strong differences in preferences for taxing the lower three income groups (the `hard work' group has slightly lower elasticities for taxing the poor), there are strong differences in preferences for taxing the rich. Respondents who believe luck plays a role in economic success are more strongly progressive, although preferences over taxing the \$175K--\$375K bracket are relatively flat'' (12). In these examples, the differences between conditional AMCEs are used as a way of descriptively characterizing differences in \textit{preferences} between the groups rather than differences in \textit{causal effects on preferences} in the groups.

As a more complete example, the upper panel of Figure \ref{fig:tkr_replication} shows AMCEs for \citeauthor{TeeleKallaRosenbluth2018}'s candidate choice experiment separately for Democratic and Republican voters, as provided in the original paper, and the lower panel shows the results using conditional marginal means. Again, we opt for visual presentation of results; tabular presentation of AMCEs, marginal means, and associated standard errors for all examples are included in the Appendix. Respondents' preference for female candidates is very apparent in both forms of analysis. Yet the discrepancy between the differences in preferences (i.e., conditional marginal means) and the differences in conditional AMCEs can be seen very clearly in the ``political experience'' feature in Figure \ref{fig:tkr_replication} (the second set of estimates from the top in both panels). The conditional AMCEs in the upper panel correctly convey that both Democrats and Republicans are more likely to favor experienced than inexperienced candidates. Reading the AMCEs descriptively, however, would suggest that Democratic voters are more favorable toward candidates with all levels of experience compared to Republican voters (i.e., Republicans and Democrats differ in their preferences over experienced candidates). In reality, however, the conditional marginal means shown in the lower panel demonstrate that actually Democrats and Republicans have very similar preferences toward candidates with 1 or 3 years of experience, but differ dramatically in their preferences over candidates with no experience (the reference category) and those with 8 years experience. Democrats are much more sensitive to experience than are Republicans and important differences in preferences are apparent for extreme categories in the visualization of conditional marginal means, but the conditional AMCEs suggest that preferences differ at all levels of experience, when in reality they do not. The selection of a reference category is therefore hugely consequential for a descriptive reading of the AMCE results.

Interpreting conjoint AMCEs as measures of preferences is an inferential error. In a simple experiment like the party cue example just given, this kind of interpretation would be obviously flawed. A larger causal effect of the party cue for Democrats than Republicans does not necessarily mean that Democrats are more supportive than Republicans on average or in either condition. Effects are relative, not absolute, statements about preferences. Republicans, for example, might experience a smaller effect because their preferences in the control group are already very supportive, such that a large positive effect for Democrats occurs despite Democrats being less supportive than Republicans in either experimental condition. There is simply no predictable connection between subgroup causal effects and the levels of underlying subgroup preferences. This inferential error --- interpreting differences in the size of causal effects as descriptive differences in preferences --- appears to be widespread in published conjoint analyses. While AMCEs do provide insight into the descriptive variation in preferences within-group and across-features, and conditional AMCEs do estimate the size of causal effects of features within groups, AMCEs cannot provide direct insight into the pattern of preferences between groups because they do not provide information about \textit{absolute} levels of favorability toward profiles with each feature (or combination of features).

This additional information matters. Consider again the simple two-condition experiment in which the effect of a cue treatment, $x \in {0,1}$, is compared across a single two-category covariate, $z \in {0,1}$ such as Democratic or Republican self-identification. Subgroup regression equations to estimate effects for each group are:

\begin{align*}
\hat{y} &= \beta_0 + \beta_1 x, \quad \forall z = 0 \\
\hat{y} &= \beta_2 + \beta_3 x, \quad \forall z = 1
\end{align*}

\noindent The effect of $x$ when $z=0$ is given by $\beta_1$. The effect of $x$ when $z=1$ is given by $\beta_3$. These are, in essence, the conditional AMCEs in a conjoint analysis. Yet the difference in AMCEs ($\beta_3 - \beta_1$) is not equal to the difference in preferences between the two groups, which is $\bar{y}_{z=1|x=1} - \bar{y}_{z=0|x=1}$ (estimated by $(\beta_2 + \beta_3) - (\beta_0 + \beta_1)$). The difference-in-AMCEs only equals the difference in preferences when $\beta_2 \equiv \beta_0$. Yet the standard AMCE-centric conjoint analysis does not present or characterize either of these quantities. Similarity of conditional AMCEs therefore only convey similarity of the \textit{causal effect} of the feature, but do not convey similarity of \textit{preferences} unless preferences toward profiles with the reference category are equivalent across groups. Given the reference category choice is typically arbitrary or driven by substantive knowledge of the levels, there is never any reason to expect that an arbitrarily selected reference category satisfies that equality assumption. When using a difference-in-AMCEs comparison to estimate a difference in preferences, the size and direction of the bias is determined by the size of the difference in preferences toward the reference category within each subgroup.

<<bms_difference_comparison, dependson=c("data_bms"), fig.width=8, fig.height=4, fig.cap="Estimated Preference Differences between Inequity Averse and Non-Averse Respondents from Ballard-Rosa et al. (2016) Tax Preference Experiment for Each Possible Reference Category">>=
# reported results
main <- cj(bms[!is.na(bms$ineq_averse_dum),], chose_plan ~ taxrate6, id = ~ ID, estimate = "amce_diff", by = ~ ineq_averse_dum)
main$statistic <- "Originally Reported Difference"

# AMCE differences
amce_diffs <- do.call("rbind", lapply(levels(bms$taxrate6)[-1], function(x) {
    tmp <- bms[!is.na(bms$ineq_averse_dum),]
    tmp$taxrate6 <- relevel(tmp$taxrate6, x)
    cj(tmp, chose_plan ~ taxrate6, id = ~ ID, estimate = "amce_diff", by = ~ ineq_averse_dum)
}))
amce_diffs$statistic <- "Potential Differences in AMCEs"

# Difference in Marginal Means
mm_diff <- cj(bms, chose_plan ~ taxrate6, id = ~ ID, estimate = "mm_diff", by = ~ ineq_averse_dum)
mm_diff$statistic <- "Difference in MMs"

# Merge
diffs <- rbind(main, amce_diffs, mm_diff)
levels(diffs$statistic) <- c("Originally Reported Difference", "Potential Differences in AMCEs", "Difference in MMs")
# Plot
ggplot(diffs, aes(x = estimate, y = level, group = statistic, colour = statistic, fill = statistic, shape = statistic)) +
  geom_vline(xintercept = 0, colour = "black") +
  geom_point(position = ggstance::position_dodgev(height = 0.25), size=2) +
  geom_errorbarh(aes(xmin = lower, xmax = upper),  
                 size = 0.2, height = 0,
                 position = ggstance::position_dodgev(height = 0.25)) + 
  scale_colour_manual("Statistic", limits = levels(diffs$statistic),
                      values = c("black", "gray", "black"),
                      guide = ggplot2::guide_legend(title = "Statistic")) +
  scale_fill_manual("Statistic",
                    limits = levels(diffs$statistic),
                    values = c("black", "gray", "black"),
                    guide = ggplot2::guide_legend(title = "Statistic")) +
  scale_shape_manual("Statistic",
                     limits = levels(diffs$statistic),
                     values = c(20, 16, 23),
                     guide = ggplot2::guide_legend(title = "Statistic")) +
  scale_x_continuous(limits = c(-.4,.4), oob = scales::rescale_none) +
  ylab("") +
  xlab("Estimated Difference between Inequity Averse and Non-Averse Respondents") + 
  theme_minimal() + 
      ggplot2::theme(
        legend.position = "bottom",
        panel.grid.major = ggplot2::element_blank(),
        panel.grid.minor = ggplot2::element_blank()
      )
  
rm(main, mm_diff, amce_diffs, diffs)
@

We can see this bias clearly in a reanalysis of \citeauthor{BallardRosaMartinScheve2016}'s tax preference experiment. Figure \ref{fig:bms_difference_comparison} shows an analysis for the feature capturing the tax rate for the highest earners (those over \$375,000 per year) replicating a portion of the results they present comparing inequity averse and non-averse respondents \citet[9 figure 2]{BallardRosaMartinScheve2016}. The original analysis was presented as conditional AMCEs for the two subgroups with inequity averse respondents having positive AMCEs for all tax levels (relative to 5\% as the reference category) and AMCEs for non-averse respondents being largely indistinguishable from zero. Figure \ref{fig:bms_difference_comparison} presents the implied difference-in-AMCEs from the original analysis as round black dots, demonstrating the substantial and positive \textit{apparent} differences between the two groups. The black diamonds show the true differences in marginal means between the two groups. The gray dots represent the alternative differences-in-AMCEs that could have been generated from alternative choices of reference category using the same data. Because respondents in the two groups actually have substantially different preferences over the reference category 5\% tax rate (inequity averse respondents are much less favorable toward this rate than non-averse respondents) differences-in-AMCEs make it seem like inequity averse respondents are much \textit{more} favorable toward 15\% and 25\% tax rates than non-averse respondents, when in actuality averse respondents are \textit{less} favorable toward the 15\% tax rate than non-averse respondents and the two groups have largely similar views of a 25\% tax rate. Not only does the difference-in-AMCEs overestimate group differences for very high tax rates (35\%, 45\%, 55\%) but the difference-in-AMCEs flips the true direction of group differences for lower rates. The authors correctly read their data as showing ``support for more progressive preferences is correlated with concern over societal inequality'' \citep[9]{BallardRosaMartinScheve2016} but for the wrong reason: inequity averse and non-averse respondents are similarly favorable toward middling tax rates and diverge in their views of very high and very low rates for high earners.

It is worth highlighting two further features in Figure \ref{fig:bms_difference_comparison}. First, the alternative differences-in-AMCEs estimates vary mechanically around the difference in marginal means, as the reference category varies. The difference between marginal means for two groups are always fixed in the data, so the differencing of subgroup AMCEs is merely an exercise is centering those differences at arbitrary points along the range of observed differences in marginal means. Differences-in-AMCEs for a given feature level are therefore necessarily sometimes positive and sometimes negative, depending on the reference category used in estimating them. The direction of the difference per se conveys no information about underlying pattern of preferences in the two groups. Yet the choice of reference category --- likely unintentionally --- resulted in the most extreme, positive difference-in-AMCEs that could be estimated from the data but alternative reference categories could have conveyed different, equally incorrect insights.

Second, and more practically, because there is no category for which the preferences of the two subgroups in this example are identical, no choice of reference category would have led to inferences from differences-in-AMCEs that accurately reflect the underlying difference in preferences. Even in the 25\% tax rate category, the difference between the two groups is slightly negative. Were there a category for which preferences were equivalent, that could be sensibly chosen as the reference category in order to be able to interpret differences-in-AMCEs as differences in preferences. There is never any guarantee, however, that such a reference category exists in any given experimental dataset. If multiple subgroup analyses are performed, it is unlikely the same reference category would work well across all analyses, making consistent interpretation difficult. As such, even if the AMCEs are similar, it does not necessarily mean that \textit{preferences} are similar; if AMCEs are dissimilar, it does not necessarily mean that preferences differ.

Ultimately, it is important to note that because conjoint analysis generates a sparse feature matrix (where there is never any guarantee that a particular combination of feature levels is observed in the data), it is also not possible to empirically select an appropriate set of reference categories using the data. It is impossible to know which cell --- of the tens of thousands in the design --- is the best choice of reference. This is because while it might seem possible to select a \textit{marginally} appropriate reference category (i.e., one where preferences are similar with respect to a given feature), preferences toward that reference category may differ across other dimensions in the analysis. And it is furthermore possible that there is no such cell for which preferences are identical in the two groups; such a cell may exist, but there is no reason to expect that it should exist in any given application. Thus, there is no way to use conditional AMCEs or differences between those conditional AMCEs to convey the underlying similarity or differences in preferences across sample subgroups.


\section*{Improved Analysis of Subgroup Preferences in Conjoint Designs}\label{sec:marginalmeans}

<<hainmueller_subgroup_example, dependson=c("data_hainmueller_immigration")>>=
# estimates benchmarked to largest difference between subgroups
hainmueller.A <- hainmueller_immigration
    hainmueller.A$Education <- relevel(hainmueller.A$Education, "No formal education")
    hainmueller.A$Gender <- relevel(hainmueller.A$Gender, "male")
    hainmueller.A$CountryOfOrigin <- relevel(hainmueller.A$CountryOfOrigin, "Mexico")
    hainmueller.A$ReasonForApplication <- relevel(hainmueller.A$ReasonForApplication, "Escape political/religious persecution")
    hainmueller.A$Job <- relevel(hainmueller.A$Job, "Doctor")
    hainmueller.A$JobExperience <- relevel(hainmueller.A$JobExperience, "More than five years of job training and experience")
    hainmueller.A$JobPlans <- relevel(hainmueller.A$JobPlans, "Has no plans to look for work at this time")
    hainmueller.A$PriorEntry <- relevel(hainmueller.A$PriorEntry, "Entered the U.S. once before without legal authorization")
    hainmueller.A$LanguageSkills <- relevel(hainmueller.A$LanguageSkills, "spoke [language] and used an interpreter")
# estimates benchmarked to smallest difference between subgroups
hainmueller.B <- hainmueller_immigration
    hainmueller.B$Education <- relevel(hainmueller.B$Education, "Equivalent to completing a college degree")
    hainmueller.B$Gender <- relevel(hainmueller.B$Gender, "female")
    hainmueller.B$CountryOfOrigin <- relevel(hainmueller.B$CountryOfOrigin, "Iraq")
    hainmueller.B$ReasonForApplication <- relevel(hainmueller.B$ReasonForApplication, "Reunite with family members already in the U.S.")
    hainmueller.B$Job <- relevel(hainmueller.B$Job, "Child care provider")
    hainmueller.B$JobExperience <- relevel(hainmueller.B$JobExperience, "No job training or prior experience")
    hainmueller.B$JobPlans <- relevel(hainmueller.B$JobPlans, "Does not have a contract with a U.S. employer")
    hainmueller.B$PriorEntry <- relevel(hainmueller.B$PriorEntry, "Never been to the U.S.")
    hainmueller.B$LanguageSkills <- relevel(hainmueller.B$LanguageSkills, "spoke broken English")
# formula
f1 <- ChosenImmigrant ~ LanguageSkills + CountryOfOrigin + Job + Education + JobExperience + JobPlans + ReasonForApplication + PriorEntry + Gender  + Education:Job + CountryOfOrigin:ReasonForApplication
# estimate
amce_by_ethnocentrism_1 <- cj(hainmueller.A, f1, id = ~ CaseID, estimate = "amce", by = ~ ethnocentrism_split)
amce_by_ethnocentrism_2 <- cj(hainmueller.B, f1, id = ~ CaseID, estimate = "amce", by = ~ ethnocentrism_split)
#amce_by_ethnocentrism_3 <- cj(hainmueller_immigration, f1, id = ~ CaseID, estimate = "amce", by = ~ ethnocentrism_split)
# tag datasets and merge
amce_by_ethnocentrism_1$dataset <- "A"
amce_by_ethnocentrism_2$dataset <- "B"
#amce_by_ethnocentrism_3$dataset <- "C"
amce_ref_example_merged <- rbind(amce_by_ethnocentrism_1, amce_by_ethnocentrism_2)
@

<<hainmueller_subgroup_example_plot, dependson=c("data_hainmueller_immigration", "hainmueller_subgroup_example"), fig.width=8, fig.height=12, fig.cap="Comparison of AMCEs for Low- and High-Ethnocentrism Respondents Using Two Alternative Reference Categories Choices for Hainmueller et al. (2014) Immigration Experiment", message=FALSE>>=
plot(amce_ref_example_merged, group = "ethnocentrism_split", feature_headers = FALSE, legend_title = "Ethnocentrism", vline = 0) + 
  scale_colour_manual("Ethnocentrism", limits = c("high", "low"), values = c("Red", "Blue")) +
  facet_grid(rows = vars(feature), cols = vars(dataset), scales = "free_y", space = "free_y", labeller = function(x) label_value(x, multi_line = FALSE)) +
  theme(strip.text.x = element_text(size = 8),
        strip.text.y = element_text(size = 5))
@

We have shown that subgroup analyses of conjoint designs frequently entail the use of difference-in-AMCE comparisons and we have also shown that such analyses, counterintuitively, do not demonstrate differences in preferences between groups due the near-impossibility of selecting a non-arbitrary reference category against which to estimate AMCEs. Thus the choice of reference category --- while seemingly irrelevant --- has dramatic inferential consequences in conjoint analyses. Here we provide a more complete example, demonstrating the full extent of this problem for interpretation of conjoint results and present alternative forms of analysis that more robustly convey subgroup preferences and the differences (if any) between them. Consider the left and right facets of Figure \ref{fig:hainmueller_subgroup_example_plot}, which show the exact same analysis (comparing AMCEs for high and low ethnocentrism respondents) on the same experimental data from \citeauthor{HainmuellerHopkinsYamamoto2014}'s immigration experiment. In panel ``A'' (left), all features are configured so that the reference category is the one with the largest difference in preferences between the two subgroups. In panel ``B'' (right), all features are configured so that the reference category is the one with the smallest difference in preferences between the two subgroups.\footnote{The appendix contains comparable plots for experiments by \citet{BallardRosaMartinScheve2016} and \citet{TeeleKallaRosenbluth2018}.}

Panel A gives the impression that there are significant differences in preferences between high and low ethnocentrism respondents toward immigrants from different countries of origin, with different careers, and with different educational attainments. By contrast, Panel B gives the impression that these differences --- indeed all differences --- are negligible. The experimental data and analytic approach in the two portrayals is identical; the only difference is the choice of reference category for the profile features. Given what we have shown about the relationship between differences in conditional AMCEs and differences in conditional marginal means, Panel B is the more truthful visualization \citep{Cairo2016}. The differences between subgroup AMCEs there more accurately convey differences in underlying preferences because the reference categories used in Panel B are the most similar between the two groups. Yet even this may not \textit{perfectly} convey differences because no feature generates perfect agreement between the subgroups.

<<hainmueller_mm_by_ethnocentrism, dependson=c("data_hainmueller_immigration"), fig.height = 14, fig.width=10, fig.cap="Conditional Marginal Means, by Ethnocentrism, for Hainmueller et al.'s (2014) Immigration Experiment", message=FALSE>>=
mm_by_ethnocentrism <- cj(subset(hainmueller_immigration, !is.na(ethnocentrism_split)), ChosenImmigrant ~ Gender + Education + LanguageSkills + CountryOfOrigin + Job + JobExperience + JobPlans + ReasonForApplication + PriorEntry, id = ~ CaseID, estimate = "mm", by = ~ ethnocentrism_split)
plot(mm_by_ethnocentrism,
     group = "ethnocentrism_split",
     legend_title = "Ethnocentrism",
     vline = 0.5,
     xlim = c(0.2,0.8)) +
  scale_colour_manual("Ethnocentrism", limits = c("high", "low"), values = c("Red", "Blue"))
@

<<hainmueller_mm_diffs, dependson=c("data_hainmueller_immigration"), fig.height = 14, fig.width=10, fig.cap="Differences in Conditional Marginal Means, by Ethnocentrism, for Hainmueller et al.'s (2014) Immigration Experiment", message=FALSE>>=
mm_by_ethnocentrism <- cj(subset(hainmueller_immigration, !is.na(ethnocentrism_split)),
                          ChosenImmigrant ~ Gender + Education + LanguageSkills + CountryOfOrigin + Job + JobExperience + JobPlans + ReasonForApplication + PriorEntry,
                          id = ~ CaseID,
                          estimate = "mm_diff",
                          by = ~ ethnocentrism_split)
plot(mm_by_ethnocentrism, vline = 0, xlim = c(-0.3,0.3)) +
  scale_colour_manual("feature", values = rep("Black", 9))
@

Alternatively presenting subgroup differences using conditional marginal means (as in Figure \ref{fig:hainmueller_mm_by_ethnocentrism}) provides the intended descriptive comparison of subgroup preferences. Each dot and error bar represents the conditional marginal mean (and its standard error) for high ethnocentrism (in red) and low ethnocentrism (in blue) respondents. This display of conditional marginal means highlights just how similar the preferences are for the two groups. For example, in the first set of estimates, both groups of respondents display minimally positive preferences toward female immigrants and minimally negative preferences toward male immigrants, averaging across those immigrants' other profile features. The second set of estimates shows both group are also more favorable toward higher-educated immigrants and less favorable toward less-education immigrants with no visually apparent differences. The third set of estimates, related to language skills, shows again similar patterns: both groups are more favorable toward immigrants with higher English proficiency than immigrants with lower English proficiency.

These estimates are less obviously identical for the two groups but look quite close. To test for pairwise differences between high and low ethnocentrism respondents, we can calculate differences in conditional conditional marginal means at each feature level, with associated significance tests:

\begin{itemize}
<<hainmueller_mmdiffs_by_ethnocentrism, dependson=c("data_hainmueller_immigration"), results="asis">>=
mmdiffs_by_ethnocentrism <- cj(subset(hainmueller_immigration, !is.na(ethnocentrism_split)), ChosenImmigrant ~ Gender + Education + LanguageSkills + CountryOfOrigin + Job + JobExperience + JobPlans + ReasonForApplication + PriorEntry, id = ~ CaseID, estimate = "mm_diff", by = ~ ethnocentrism_split)
mmd <- mmdiffs_by_ethnocentrism[mmdiffs_by_ethnocentrism$feature == "Language Skills", c("level", "estimate", "std.error", "z", "p")]
cat(sprintf("\\item %s: %0.2f (%0.2f, $z_{\\text{diff}}$=%0.2f, $p\\leq %0.2f$)\n", mmd[[1]][1], mmd[[2]][1], mmd[[3]][1], mmd[[4]][1], mmd[[5]][1]))
cat(sprintf("\\item %s: %0.2f (%0.2f, $z_{\\text{diff}}$=%0.2f, $p\\leq %0.2f$)\n", mmd[[1]][2], mmd[[2]][2], mmd[[3]][2], mmd[[4]][2], mmd[[5]][2]))
cat(sprintf("\\item %s: %0.2f (%0.2f, $z_{\\text{diff}}$=%0.2f, $p\\leq %0.2f$)\n", mmd[[1]][3], mmd[[2]][3], mmd[[3]][3], mmd[[4]][3], mmd[[5]][3]))
cat(sprintf("\\item %s: %0.2f (%0.2f, $z_{\\text{diff}}$=%0.2f, $p\\leq %0.2f$)\n", mmd[[1]][4], mmd[[2]][4], mmd[[3]][4], mmd[[4]][4], mmd[[5]][4]))	
@
\end{itemize}

<<hainmueller_language_diffs, dependson=c("data_hainmueller_immigration"), eval=TRUE, echo=FALSE>>=
hainmueller_anova_language <- cj_anova(subset(hainmueller_immigration, !is.na(ethnocentrism_split)), ChosenImmigrant ~ LanguageSkills, id = ~ CaseID, by = ~ ethnocentrism_split)
@

\noindent These pairwise tests show that are our eyes have not deceived us. None of the level-specific differences in conditional marginal means are statistically distinguishable from zero. Were we interested in an omnibus tests of whether any of these differences were non-zero, we could perform a nested model comparison of two equations: (a) one estimating only marginal effects of the ``Language Skills'' feature, and (b) the same model with additional interactions between the subgrouping covariate and the features. The resulting F-test for the model comparison in this case again gives us little reason to believe there are subgroup differences: \Sexpr{sprintf("F(%d)=%0.2f, $p\\leq%0.2f$", hainmueller_anova_language$Df[2], hainmueller_anova_language$F[2], hainmueller_anova_language$"Pr(>F)"[2])}. We could repeat such pairwise comparisons or omnibus comparisons for each feature in the design.

Furthermore, we could also directly visualize differences in conditional marginal means for this feature --- and all features --- as in Figure \ref{fig:hainmueller_mm_diffs}. This provides a more direct presentation of \textit{differences} between subgroup preferences as the vertical line indicates feature levels for which there is no difference between the two groups. Positive values to the right of the line indicate positive differences (high ethnocentrism respondents are more favorable toward immigrants with this feature than low ethnocentrism respondents) and negative value to the left of zero convey the opposite. A further advantage of this plot is that unlike displays of conditional AMCEs, differences in conditional marginal means communicate subgroup differences for all feature levels including the reference categories. This display makes readily clear what was only indirectly apparent in Figure \ref{fig:hainmueller_mm_by_ethnocentrism}: there are indeed no sizeable and only a few statistically apparent differences in preferences between the two groups.

<<nested_model, dependson=c("data_hainmueller_immigration"), eval=TRUE, echo=FALSE>>=
hainmueller_anova_all <- cj_anova(subset(hainmueller_immigration, !is.na(ethnocentrism_split)), ChosenImmigrant ~ Gender + Job*Education + LanguageSkills + CountryOfOrigin*ReasonForApplication + JobExperience + JobPlans + PriorEntry, id = ~ CaseID, by = ~ ethnocentrism_split)
@

As before, we can perform an omnibus tests for the presence of any subgroup differences across all features, again using nested model comparison of two equations: (a) one estimating only effects of the features, and (b) the same model with additional interactions between the subgrouping covariate and all features. The result of that test for differences by ethnocentrism from the immigration experiment is: \Sexpr{sprintf("F(%d)=%0.2f, $p\\leq%0.2f$", hainmueller_anova_all$Df[2], hainmueller_anova_all$F[2], hainmueller_anova_all$"Pr(>F)"[2])}, which further demonstrates that the substantive interpretation provided by \citet{HainmuellerHopkinsYamamoto2014} accurately identified a lack of between-group differences. This kind of test can also be used to assess heterogeneity across conjoint features. For example, \citet{TeeleKallaRosenbluth2018} report just such a test for how effects of features other than candidate sex may differ between male and female candidates, finding no such heterogeneity (8--9). Fortunately, the original analysis accurately detected an absence of subgroup differences, yet a subtly different set of analytic decisions about reference categories (as shown in Figure \ref{fig:hainmueller_subgroup_example_plot}) could have led to an quite different conclusion.

\section*{Conclusion}\label{sec:conclusion}

This article has identified several challenges related to the analysis and reporting of conjoint experimental designs, particularly analyses of subgroup differences. We suggest that conjoint analyses should report not only average marginal component effects (AMCEs) but also descriptive quantities that better convey underlying preferences over profile features and better convey subgroup differences in those preferences. Our intention here is not to substantively undermine any previous set of results but instead to urge researchers moving forward to demonstrate considerable caution in how they design, analyze, and present the results of these types of experiments. We have relatively straightforward and hopefully uncontroversial advice for how analysts of conjoint experiments should proceed:

\begin{enumerate}
\item Always report unadjusted marginal means when attempting to provide a \textit{descriptive} summary of respondent preferences in addition to or instead of AMCEs.\footnote{Like the presentation of AMCEs, displaying marginal means in constrained conjoint designs may also distort apparent patterns given that not all features can co-occur. Partitioning the design into fractions such that each fraction contains a fully unconstrained design would mitigate any concern with that presentation.}

\item Exercise caution when explicitly or implicitly interpreting differences-in-AMCEs across subgroups. While that quantity conveys the difference in effects of a change in a given feature, heterogeneous effects do not necessarily mean different underlying preferences. Differences-in-AMCEs are almost always a biased estimate (of unknown sign and direction) of the difference in underlying preferences. If differences in AMCEs are reported, the choice of reference categories should be discussed explicitly and diagnostics should be provided to justify it.

\item When descriptively characterizing differences in preferences between subgroups, directly estimate the subgroup difference using conditional marginal means and differences between conditional marginal means, rather than relying on the difference-in-AMCEs.

\item To formally test for group differences in preferences, regression with interaction terms between the subgrouping covariate and all feature levels will generate estimates of level-specific differences in preferences via the coefficients on the interaction terms.\footnote{The analysis is slightly more complicated in constrained designs.} A nested model comparison between this equation against one without such interactions provides an omnibus test of subgroup differences, which should be reported when characterizing overall patterns of subgroup differences.
\end{enumerate}

\noindent Following this advice, we hope, will allow researchers to more clearly and more accurately represent descriptive results of conjoint experiments.

The popularity of conjoint analyses in recent years highlights the power of the design and the important contributions made by \citet{HainmuellerHopkinsYamamoto2014} in providing a novel causal interpretation of these fully randomized factorial designs. Yet with new tools always come new challenges. The now-common practice of descriptively interpreting conjoints requires more caution than is immediately obvious. This paper has demonstrated several such challenges and hopefully provides useful advice for how researchers should proceed with the analysis of such designs.

To facilitate such analysis and, especially, to provide easy-to-use tools for calculating marginal means and performing reference category selection diagnostics, we provide software called \textbf{cregg} \citep{Leeper2018cregg} that will perform these analyses and also provides the simple-to-use visualization tools used throughout this article. With that resource in-hand, researchers should be well-equipped to analyze conjoint designs without running into the analytic challenges discussed here.



\singlespacing
\bibliographystyle{apsa-leeper}
\bibliography{references}
\clearpage


\appendix
\tableofcontents



\clearpage

\section{Definition of Quantities of Interest}\label{app:quantities}

A conjoint experiment serves two purposes: (1) description of the conditional distribution of favorability over variations in multiple features, and (2) leveraging the random observation of combinations of features (so-called ``profiles'') to infer that any differences in favorability over features are causally attributable to the features as opposed to something else. The quantities of interest are therefore functions of the features being randomized as in any factorial experiment. But additionally, conjoints typically involve within-subjects research designs (i.e., multiple, different profile observations per participant) thus necessitating some additional notation to account for the \textit{survey implementation} of the conjoint in addition to the definition of the descriptive and causal parameters of interest.

Ultimately, a conjoint since \citet{HainmuellerHopkinsYamamoto2014} is a complex survey-experimental design involving multiple observations across a high-dimension factorial experimental space. Specifically, $I$ respondents ($i \in \{1, \dots, I\}$) are presented with $K$ rating or forced choice decision tasks, each involving $J$ (typically 2) alternative profiles of, for example, candidates or policies. Each profile consists of a vector of $F$ (typically discrete) features or attributes that describe the profile (e.g., age, sex), each composed of $D_f$ alternative levels, a number which can vary across features. The experiment thus generates a dataset with $N = I \times J \times K$ observations of some rating scale or discrete choice outcome, $Y$, from a random sample of profiles drawn from the $C = \prod_{f = 1}^{F} D_f$ population of experimental \textit{cells} in the $F$-dimension feature space.

The survey implementation of the conjoint therefore generates $N$ observations that can be indexed by $i,j,k$, forming an $N \times(L+4)$ dimensional data matrix $\mathbf{M}$ with each row representing the vector of feature levels $\vec{F}$ in each profile $j$ of respondent $i$'s task $k$, with indicators for $i$, $j$, $k$, and the corresponding outcome $Y_{i,j,k}$.\footnote{In typical paired designs (where $J=2$), this means each task generates two data points: $Y_{i,1,k}$ and $Y_{i,2,k}$. Note, too, that in fully randomized designs, these two profiles can be identical. Furthermore in fully randomized, forced-choice designs this can yield the additional curiosity that $Y_{i,\mathbf{c}} \neq Y_{i,\mathbf{c}}$ for a given respondent, $i$, and profile, $\mathbf{c}$.}

With no loss of information, we can think of each row in this matrix equivalently as an observation of $Y_{i,\vec{F}}$. This is because \citet{HainmuellerHopkinsYamamoto2014} make several important assumptions that allow us to interpret these data in a different way than the survey implementation implies. First, they assume no carryover effects (Assumption 1), such that multiple observations from the same respondent can be treated as independent of one another. Second, they assume no profile order effects within-task (Assumption 2), such that profiles within a task can be treated as independent of each other. Assumptions 1 and 2 imply that the survey implementation indices for task, $k$, and profile-within-task, $j$, can be ignored. They have no bearing on any quantity of interest, by assumption. 

The analyst is therefore left with a dataset of $N$ observations, grouped into $i$ participants, each providing into $Y_{\vec{F}}$. All quantities of interest must therefore be specified over as features of the distribution of $Y$ over the $F$-dimensional feature space. In what follows, we therefore focus on the experimental features being randomized rather than the survey design factors being assumed away. \citet{HainmuellerHopkinsYamamoto2014} make a third assumption that profiles are randomly constituted (Assumption 3), which in a fully randomized design, has the effect of meaning that features and feature combinations are randomly sampled for observation. If this randomization is uniform (which it almost always is in applied examples) this means we can additionally ignore the probability of observing any given combination (as all profiles are equally likely to be observed). This is a point we return to in a moment.

The most basic thing that can be learned about the distribution of $Y$ is the expected value, $E[Y]$, or \textit{grand mean} (in the parlance of factorial experiments). We can think of this quantity in terms of the survey implementation process (namely, respondents, tasks, and profiles) or as a simple function of the resulting data:

\begin{equation}
\bar{Y} = \dfrac{1}{I \times J \times K} \sum_{i=1}^{I} \sum_{j=1}^{J} \sum_{k=1}^{K} Y_{i,j,k} = \dfrac{1}{N} \sum_{n=1}^{N} Y_n
\end{equation}

\noindent The nested summation over $i,j,k$ could be stated explicitly but is unnecessary as the grand mean is simply the mean of all observed $Y$. A useful check on intuition is that in a forced choice design, where a respondent must choose only one profile, $j$, of all those presented in each task $k$, then by design $\bar{Y} = \frac{1}{J}$. For common, two-alternative, forced choice designs, $\bar{Y}$ therefore always equals $0.5$. By contrast, in rating scale designs, $\bar{Y}$ can take any value between the lower and upper bounds of the rating scale.

In an experiment where $N > C$ (the number of observations is larger than the number of cells) due to a large sample, or few factors, or levels of each factor, or both (or both of these design characteristic), a sensible next quantity of interest is the \textit{cell mean}: $E[Y|\vec{X} = \vec{x}]$, which in a conjoint simply measures the mean favorability toward a particular profile, $\vec{x}$. An effort to actually estimate this quantity will, however, become obviously intractable when one recognizes that the number of observations in a typical conjoint is much lower the number of feasible profiles ($N \ll C$). The cell mean can be unobserved for many or perhaps most experimental cells. 

Therefore quantities of interest that derive from it --- such as pairwise differences of means between cells --- cannot be estimated for any of the arbitrary $\binom{C}{2}$ pairs of cells. As an example, in the \cite{HainmuellerHopkinsYamamoto2014} candidate experiment, $C = 6^6 * 2^2 = 186,624$ and $N = 3466$, so less than 2\% of experimental cells were observable and a minuscule fraction of the 17.4 billion pairwise cell combinations could have generated estimable effects. 

It is at this point that the quantities of interest in a conjoint can become confusing. In a typical experiment where $N > C$, these pairwise differences of means are the standard estimator for a causal effect. For example, we might be interested in the effect on $Y$ of changing the value of one feature to another theoretically interesting value of that feature, holding all other feature values in the profile constant:

\begin{equation}
\tau = E[Y|X_1=x_1,X_2=x_2,\dots,X_f=x_f] - E[Y|X_1= \neg x_1,X_2=x_2,\dots,X_f=x_f]
\end{equation}

\noindent but we have no guarantee that both or, in fact, either of those particular cells are observed. If even this minimal causal quantity cannot be guaranteed to be estimable by design, questions about higher-order interactions across features are even more difficult to estimate as they require observing four or more specific cells, any of which may be missing. Even if we were interested in such quantities, we would be unlikely to be able to estimate them.

Conjoint designs therefore ask us to think about completely different quantities of interest from typical sentiment measurement or experimentation. Consequently, what quantities might we care about that can be estimated from an $L$-dimension factorial experimental with considerable sparsity other than the grand mean? 

Even though $N \ll C$ in most applied conjoints, $N > F$. This means that even if we probably cannot learn about particular high-dimensional \textit{combinations of features}, we can learn about favorability toward particular features alone. That is, we can learn about conditional expectations over each feature dimension, $E[Y|X_f=x_f]$. In the factorial experiments literature, this conditional mean is called the \textit{marginal mean} (as it lies at the margins of a tabular presentation cell means for the complete design). The uniform sampling of cells in the design means that this is quantity can be estimated by the simple mean of $Y \forall X_f = x_f$. Were a constrained conjoint design used where some feature combinations were impossible, the marginal means would only be intelligible in the fractions of the design where all cells are observed.\footnote{Practically, the random sampling of cells does not need to be uniform; over- and under-representation of cells is possible. We focus here on fully randomized designs that draw profiles from the full space with equal probability. A nuance in \citeauthor{HainmuellerHopkinsYamamoto2014}'s notation is that their quantities of interest are conditioned on an arbitrary joint distribution of features rather than the particular joint distribution of features that was used to construct design or the joint distribution of features that happens to emerge empirically. In other words, they weight cells by an arbitrary joint probability mass function.}

To clarify this point, consider the constrained 2x3 design below where one cell is unobserved by design:

\begin{center}
\begin{tabular}{lccc}\toprule
 & $A = 1$ & $A = 2$ & \\ \midrule
$B = 1$ & $Y_{A=1, B=1}$ & $Y_{A=2, B=1}$ & $E[Y|B=1]$ \\
$B = 2$ & $Y_{A=1, B=2}$ & $Y_{A=2, B=1}$ & $E[Y|B=2]$ \\
$B = 3$ & $Y_{A=1, B=3}$ & -- & $E[Y|B=3]$ \\ \midrule
 & $E[Y|A=1]$ & $E[Y|A=2]$ & $E[Y]$ \\ \bottomrule
\end{tabular}
\end{center}

\noindent Were the lower-right cell ($A=2, B=3$) observable by design, then a direct comparison of the marginal means, $E[Y|A=1]$ and $E[Y|A=2]$, in the lower table margin would provide direct insight into the relative favorability of respondents to profiles with features $A=1$ and $A=2$, marginalized over $B$. But because this cell is unobserved, these marginal means marginalize over different subsets of the possible values of $B$ making them not obviously comparable. By contrast, the first and second marginal means at the top-right of the table --- $E[Y|B=1]$ and $E[Y|B=2]$ --- provide insight into the favorability of participants toward profiles with features $B=1$ and with feature $B=2$ marginalizing over the two possible values of $A$. A researcher could safely conclude that participants are more (less) favorable toward profiles with feature $B=1$ than $B=2$ from this information alone. But they would not be able to so for feature $A$ without either (a) an explicit caveat that the comparison is of dissimilar subsets of profiles along dimension $B$ or (b) calculating marginal means over only the completely observable\footnote{Note that what matters here is \textit{observability}, not whether any given cell is actually observed. We know from above that most cells will be unobserved even in a uniformly sampled, unconstrained design.} portion of the feature space.

For the common \textit{descriptive} use of conjoint designs to measure preferences over multi-dimensional objects, these marginal means alone are of direct interest. They express favorability on the scale of the outcome over alternative values of each feature.

For the \textit{causal} interpretation of conjoint designs, comparisons of these marginal means is required. Comparisons between them provide causal inferences about the effect of changing a focal feature, marginalizing across the distribution of other features. Because feature combinations (i.e., the profiles) are randomly constructed and randomly observed from all possible combinations, the distribution of other non-focal features is, in expectation, is independent of the focal feature, thus identical across all levels of the focal feature, and therefore ignorable. A typical causal effect of interest is therefore the difference in marginal means across two levels of a feature. For an unconstrained design, this difference is the \textit{average marginal component effect} (AMCE) defined by \citet{HainmuellerHopkinsYamamoto2014}. In this way, an AMCE is simply a marginal effect of the factorial design: the difference of two marginal means.

Unfortunately, this is not a perfectly complete definition, but it covers the vast majority of applied cases. The exceptions are few. First, \citeauthor{HainmuellerHopkinsYamamoto2014} allow the joint distribution of features used in calculating the difference of marginal means to be arbitrary. This is meant to accommodate the weighting of effects to reflect the real-world distribution of feature combinations (e.g., down-weighting African American Republican political candidates given their rarity in real-world politics) but in practice this is uncommon.

Second, in constrained designs where some cells are unobservable, care needs to be taken in both defining and estimating AMCEs. Take, for example, the trivial example just above. The difference $E[Y|B=2]-E[Y|B=1]$ marginalizes over the full set of levels of $A$ but $E[Y|B=3]-E[Y|B=1]$ marginalizes only over case where $A=1$. \citeauthor{HainmuellerHopkinsYamamoto2014} allow for these two differences to be presented as the AMCE despite the fact that the quantities marginalize over distinct subsets of the design. For example, if feature $A$ is race ${Caucasian, African American}$ and feature $B$ is religion ${Evangelical, Catholic, Jewish}$. In \citeauthor{HainmuellerHopkinsYamamoto2014}'s notation, the AMCE of a candidate being Jewish relative to being Evangelical Christian is defined only for Caucasian candidates, while the AMCE of being Catholic is defined for both African American and Caucasian candidates. There is nothing inherently problematic about that but, as noted earlier, it requires either being clear about what features are being marginalized over or an analysis of only the complete and comparable subset of the design. So, researchers using such designs may prefer to not present the AMCE of being Jewish together with the other results as it does not draw upon the complete set of feature combinations used in other portions of the analysis.



\clearpage

\section{Hainmueller et al. (2014) Immigration Experiment}

\subsection{Replication using AMCEs}

<<hainmueller_immigration_amce_appendix, dependson=c("data_hainmueller_immigration"), fig.height=8, fig.width=8>>=
plot(
  cj(
   hainmueller_immigration, 
   ChosenImmigrant ~ Gender + Education + LanguageSkills + CountryOfOrigin + Job + JobExperience + JobPlans + ReasonForApplication + PriorEntry + Education:Job + CountryOfOrigin:ReasonForApplication,
   id = ~ CaseID
  )
)
@

\clearpage

<<hainmueller_amce_table, dependson=c("data_hainmueller_immigration"), results="asis">>=
print(xtable::xtable(
  cj(
     hainmueller_immigration, 
     ChosenImmigrant ~ Gender + Education + LanguageSkills + CountryOfOrigin + Job + JobExperience + JobPlans + ReasonForApplication + PriorEntry + Education:Job + CountryOfOrigin:ReasonForApplication,
     estimate = "amce",
     id = ~ CaseID
  )[c("feature", "level", "estimate", "std.error", "z")],
    digits = 2, align = c("l", "l", "p{3in}", "r", "r", "r")
), include.rownames = FALSE, size = "footnotesize")
@

\clearpage

\subsection{Replication using MMs}

<<hainmueller_immigration_mm_appendix, dependson=c("data_hainmueller_immigration"), fig.height=8, fig.width=8>>=
plot(
  cj(
   hainmueller_immigration, 
   ChosenImmigrant ~ Gender + Education + LanguageSkills + CountryOfOrigin + Job + JobExperience + JobPlans + ReasonForApplication + PriorEntry + Education:Job + CountryOfOrigin:ReasonForApplication,
   id = ~ CaseID,
   estimate = "mm",
   h0 = 0.5
  ), vline = 0.5
)
@

\clearpage

<<hainmueller_mm_table, dependson=c("data_hainmueller_immigration"), results="asis">>=
print(xtable::xtable(
  cj(
     hainmueller_immigration, 
     ChosenImmigrant ~ Gender + Education + LanguageSkills + CountryOfOrigin + Job + JobExperience + JobPlans + ReasonForApplication + PriorEntry + Education:Job + CountryOfOrigin:ReasonForApplication,
     estimate = "mm",
     id = ~ CaseID,
     h0 = 0.5
  )[c("feature", "level", "estimate", "std.error", "z")],
    digits = 2, align = c("l", "l", "p{3in}", "r", "r", "r")
), include.rownames = FALSE, size = "footnotesize")
@

\clearpage

\subsection{Subgroup Analysis for Hainmueller et al. (2014) Immigration Experiment using AMCEs}

<<hainmueller_immigration_subgroup_amce_appendix, dependson=c("data_hainmueller_immigration"), fig.height=8, fig.width=8>>=
plot(
  cj(
   na.omit(hainmueller_immigration), 
   ChosenImmigrant ~ Gender + Education + LanguageSkills + CountryOfOrigin + Job + JobExperience + JobPlans + ReasonForApplication + PriorEntry + Education:Job + CountryOfOrigin:ReasonForApplication,
   id = ~ CaseID,
   by = ~ethnocentrism_split
  ), group = "ethnocentrism_split"
)
@

\clearpage

\subsection{Subgroup Analysis for Hainmueller et al. (2014) Immigration Experiment using MMs}

<<hainmueller_immigration_subgroup_mm_appendix, dependson=c("data_hainmueller_immigration"), fig.height=8, fig.width=8>>=
plot(
  cj(
   na.omit(hainmueller_immigration), 
   ChosenImmigrant ~ Gender + Education + LanguageSkills + CountryOfOrigin + Job + JobExperience + JobPlans + ReasonForApplication + PriorEntry + Education:Job + CountryOfOrigin:ReasonForApplication,
   id = ~ CaseID,
   estimate = "mm",
   h0 = 0.5,
   by = ~ethnocentrism_split
  ), vline = 0.5, group = "ethnocentrism_split"
)
@

\clearpage

\section{Hainmueller et al. (2014) Candidate Experiment}

\subsection{Replication using AMCEs}

<<hainmueller_candidate_amce_appendix, dependson=c("data_hainmueller_candidate"), fig.height=8, fig.width=8>>=
plot(
  cj(
   hainmueller_candidate, 
   selected ~ atmilitary + atreligion + ated + atprof + atinc + atrace + atage + atmale,
   id = ~ resID,
   estimate = "amce"
  )
)
@

\clearpage

<<hainmueller_candidate_amce_table, dependson=c("data_hainmueller_candidate"), results="asis">>=
print(xtable::xtable(
  cj(
     hainmueller_candidate, 
     selected ~ atmilitary + atreligion + ated + atprof + atinc + atrace + atage + atmale,
     id = ~ resID,
     estimate = "amce"
  )[c("feature", "level", "estimate", "std.error", "z")],
    digits = 2, align = c("l", "l", "p{3in}", "r", "r", "r")
), include.rownames = FALSE, size = "footnotesize")
@

\clearpage

\subsection{Replication using MMs}

<<hainmueller_candidate_mm_appendix, dependson=c("data_hainmueller_candidate"), fig.height=8, fig.width=8>>=
plot(
  cj(
   hainmueller_candidate, 
   selected ~ atmilitary + atreligion + ated + atprof + atinc + atrace + atage + atmale,
   id = ~ resID,
   estimate = "mm",
   h0 = 0.5
  ), vline = 0.5
)
@

\clearpage

<<hainmueller_candidate_mm_table, dependson=c("data_hainmueller_candidate"), results="asis">>=
print(xtable::xtable(
  cj(
     hainmueller_candidate, 
     selected ~ atmilitary + atreligion + ated + atprof + atinc + atrace + atage + atmale,
     id = ~ resID,
     estimate = "mm",
     h0 = 0.5
  )[c("feature", "level", "estimate", "std.error", "z")],
    digits = 2, align = c("l", "l", "p{3in}", "r", "r", "r")
), include.rownames = FALSE, size = "footnotesize")
@

\clearpage

\section{Ballard-Rosa et al. (2016) Tax Preference Experiment}

\subsection{Replication using AMCEs}

<<bms_amce_appendix, dependson=c("data_bms"), fig.height=8, fig.width=8>>=
plot(
  cj(bms, chose_plan ~ taxrate1 + taxrate2 + taxrate3 + taxrate4 + taxrate5 + taxrate6 + taxrev, weights = ~ weight, id = ~ ID, estimate = "amce")
)
@

\clearpage

<<bms_amce_table, dependson=c("data_bms"), results="asis">>=
print(xtable::xtable(
  cj(
    bms,
    chose_plan ~ taxrate1 + taxrate2 + taxrate3 + taxrate4 + taxrate5 + taxrate6 + taxrev,
    weights = ~ weight,
    id = ~ ID,
    estimate = "amce"
   )[c("feature", "level", "estimate", "std.error", "z")],
     digits = 2, align = c("l", "l", "p{1.5in}", "r", "r", "r")
), include.rownames = FALSE)
@

\clearpage

\subsection{Replication using MMs}

<<bms_mm_appendix, dependson=c("data_bms"), fig.height=8, fig.width=8>>=
plot(
  cj(bms, chose_plan ~ taxrate1 + taxrate2 + taxrate3 + taxrate4 + taxrate5 + taxrate6 + taxrev, weights = ~ weight, id = ~ ID, estimate = "mm", h0 = 0.5),
  vline = 0.5
)
@

\clearpage

<<bms_mm_table, dependson=c("data_bms"), results="asis">>=
print(xtable::xtable(
  cj(
    bms,
    chose_plan ~ taxrate1 + taxrate2 + taxrate3 + taxrate4 + taxrate5 + taxrate6 + taxrev,
    weights = ~ weight,
    id = ~ ID,
    estimate = "mm",
    h0 = 0.5)[c("feature", "level", "estimate", "std.error", "z")],
  digits = 2, align = c("l", "l", "p{1.5in}", "r", "r", "r")
), include.rownames = FALSE)
@

\clearpage

\subsection{Subgroup Analysis for Ballard-Rosa et al. (2016), by ``Taxes Harm Economy'' Split using AMCEs}

<<bms_subgroup_amce_appendix1, dependson=c("data_bms"), fig.width=8, fig.height=8>>=
plot(cj(subset(bms, taxes_harm_split %in% c("Help", "Harm")),
        chose_plan ~ taxrate1 + taxrate2 + taxrate3 + taxrate4 + taxrate5 + taxrate6 + taxrev,
        id = ~ID,
        weights = ~weight,
        estimate = "amce",
        by = ~ taxes_harm_econ),
     vline = 0,
     group = "taxes_harm_econ",
     legend_title = "Taxes Help/Harm Economy")
@

\clearpage

\subsection{Subgroup Analysis for Ballard-Rosa et al. (2016), by ``Taxes Harm Economy'' Split using MMs}

<<bms_subgroup_mm_appendix1, dependson=c("data_bms"), fig.width=8, fig.height=8>>=
plot(cj(subset(bms, taxes_harm_split %in% c("Help", "Harm")),
        chose_plan ~ taxrate1 + taxrate2 + taxrate3 + taxrate4 + taxrate5 + taxrate6 + taxrev,
        id = ~ID,
        weights = ~weight,
        estimate = "mm",
        h0 = 0.5,
        by = ~ taxes_harm_econ),
     vline = 0.5,
     group = "taxes_harm_econ",
     legend_title = "Taxes Help/Harm Economy")
@

\clearpage

\subsection{Subgroup Analysis for Ballard-Rosa et al. (2016), by Inequity Aversion using AMCEs}

<<bms_subgroup_amce_appendix2, dependson=c("data_bms"), fig.width=8, fig.height=8>>=
plot(cj(subset(bms, !is.na(ineq_averse_dum)),
        chose_plan ~ taxrate1 + taxrate2 + taxrate3 + taxrate4 + taxrate5 + taxrate6 + taxrev,
        id = ~ID,
        weights = ~weight,
        estimate = "amce",
        by = ~ ineq_averse_dum),
     vline = 0,
     group = "ineq_averse_dum",
     legend_title = "Inequity Aversion")
@

\clearpage

\subsection{Subgroup Analysis for Ballard-Rosa et al. (2016), by Inequity Aversion using MMs}

<<bms_subgroup_mm_appendix2, dependson=c("data_bms"), fig.width=8, fig.height=8>>=
plot(cj(subset(bms, !is.na(ineq_averse_dum)),
        chose_plan ~ taxrate1 + taxrate2 + taxrate3 + taxrate4 + taxrate5 + taxrate6 + taxrev,
        id = ~ID,
        weights = ~weight,
        estimate = "mm",
        h0 = 0.5,
        by = ~ ineq_averse_dum),
     vline = 0.5,
     group = "ineq_averse_dum",
     legend_title = "Inequity Aversion")
@

\clearpage

\subsection{Comparison of Alternative Reference Categories for Ballard-Rosa et al. (2016) Tax Preference Experiment, by ``Taxes Harm Economy'' Split}

<<bms_subgroup_example1, dependson=c("data_bms")>>=
# estimates benchmarked to largest difference between subgroups
bms.A <- bms
    bms.A$taxrate1 <- relevel(bms.A$taxrate1, "<10k: 15%")
    bms.A$taxrate2 <- relevel(bms.A$taxrate2, "10-35k: 35%")
    bms.A$taxrate3 <- relevel(bms.A$taxrate3, "35-85k: 35%")
    bms.A$taxrate4 <- relevel(bms.A$taxrate4, "85-175k: 5%")
    bms.A$taxrate5 <- relevel(bms.A$taxrate5, "175-375k: 45%")
    bms.A$taxrate6 <- relevel(bms.A$taxrate6, ">375k: 45%")
    bms.A$taxrev <- relevel(bms.A$taxrev, "<75%")
# estimates benchmarked to smallest difference between subgroups
bms.B <- bms
    bms.B$taxrate1 <- relevel(bms.A$taxrate1, "<10k: 5%")
    bms.B$taxrate2 <- relevel(bms.A$taxrate2, "10-35k: 25%")
    bms.B$taxrate3 <- relevel(bms.A$taxrate3, "35-85k: 25%")
    bms.B$taxrate4 <- relevel(bms.A$taxrate4, "85-175k: 25%")
    bms.B$taxrate5 <- relevel(bms.A$taxrate5, "175-375k: 25%")
    bms.B$taxrate6 <- relevel(bms.A$taxrate6, ">375k: 35%")
    bms.B$taxrev <- relevel(bms.A$taxrev, "95-105%")
# formula
f1 <- chose_plan ~ taxrate1 + taxrate2 + taxrate3 + taxrate4 + taxrate5 + taxrate6 + taxrev
# estimate
amce_by_harm_1 <- cj(bms.A, f1, id = ~ ID, weights = ~ weight, estimate = "amce", by = ~ taxes_harm_split)
amce_by_harm_2 <- cj(bms.B, f1, id = ~ ID, weights = ~ weight, estimate = "amce", by = ~ taxes_harm_split)
# tag datasets and merge
amce_by_harm_1$dataset <- "A"
amce_by_harm_2$dataset <- "B"
amce_ref_bms_merged1 <- rbind(amce_by_harm_1, amce_by_harm_2)
amce_ref_bms_merged1$level <- factor(amce_ref_bms_merged1$level, levels = with(bms, c(levels(taxrate1), levels(taxrate2), levels(taxrate3), levels(taxrate4), levels(taxrate5), levels(taxrate6), levels(taxrev))))
@

<<bms_subgroup_example_plot1, dependson=c("data_bms", "bms_subgroup_example1"), fig.width=10, fig.height=10, fig.caption="Alternative Reference Categories Features in Ballard-Rosa et al. (2016) Tax Preference Experiment, by ``Taxes Harm Economy'' Split">>=
plot(amce_ref_bms_merged1, group = "taxes_harm_split", feature_headers = FALSE, legend_title = "Taxes Help/Harm Economy", vline = 0) + 
  facet_grid(rows = vars(feature), cols = vars(dataset), scales = "free_y", space = "free_y", labeller = function(x) label_value(x, multi_line = FALSE)) +
  theme(strip.text.x = element_text(size = 8),
        strip.text.y = element_text(size = 5))
@

\clearpage

\subsection{Comparison of Alternative Reference Categories for Ballard-Rosa et al. (2016) Tax Preference Experiment, by Inequity Aversion}

<<bms_subgroup_example2, dependson=c("data_bms")>>=
# estimates benchmarked to largest difference between subgroups
bms.A <- bms
    bms.A$taxrate1 <- relevel(bms.A$taxrate1, "<10k: 25%")
    bms.A$taxrate2 <- relevel(bms.A$taxrate2, "10-35k: 35%")
    bms.A$taxrate3 <- relevel(bms.A$taxrate3, "35-85k: 35%")
    bms.A$taxrate4 <- relevel(bms.A$taxrate4, "85-175k: 35%")
    bms.A$taxrate5 <- relevel(bms.A$taxrate5, "175-375k: 45%")
    bms.A$taxrate6 <- relevel(bms.A$taxrate6, ">375k: 5%")
    bms.A$taxrev <- relevel(bms.A$taxrev, "105-125%")
# estimates benchmarked to smallest difference between subgroups
bms.B <- bms
    bms.B$taxrate1 <- relevel(bms.A$taxrate1, "<10k: 5%")
    bms.B$taxrate2 <- relevel(bms.A$taxrate2, "10-35k: 5%")
    bms.B$taxrate3 <- relevel(bms.A$taxrate3, "35-85k: 5%")
    bms.B$taxrate4 <- relevel(bms.A$taxrate4, "85-175k: 15%")
    bms.B$taxrate5 <- relevel(bms.A$taxrate5, "175-375k: 25%")
    bms.B$taxrate6 <- relevel(bms.A$taxrate6, ">375k: 25%")
    bms.B$taxrev <- relevel(bms.A$taxrev, "95-105%")
# formula
f1 <- chose_plan ~ taxrate1 + taxrate2 + taxrate3 + taxrate4 + taxrate5 + taxrate6 + taxrev
# estimate
amce_by_harm_1 <- cj(subset(bms.A, !is.na(ineq_averse_dum)), f1, id = ~ ID, weights = ~ weight, estimate = "amce", by = ~ ineq_averse_dum)
amce_by_harm_2 <- cj(subset(bms.B, !is.na(ineq_averse_dum)), f1, id = ~ ID, weights = ~ weight, estimate = "amce", by = ~ ineq_averse_dum)
# tag datasets and merge
amce_by_harm_1$dataset <- "A"
amce_by_harm_2$dataset <- "B"
amce_ref_bms_merged2 <- rbind(amce_by_harm_1, amce_by_harm_2)
amce_ref_bms_merged2$level <- factor(amce_ref_bms_merged2$level, levels = with(bms, c(levels(taxrate1), levels(taxrate2), levels(taxrate3), levels(taxrate4), levels(taxrate5), levels(taxrate6), levels(taxrev))))
@

<<bms_subgroup_example_plot2, dependson=c("data_bms", "bms_subgroup_example2"), fig.width=10, fig.height=10, fig.caption="Alternative Reference Categories Features in Ballard-Rosa et al. (2016) Tax Preference Experiment, by Inequity Aversion">>=
plot(amce_ref_bms_merged2, group = "ineq_averse_dum", feature_headers = FALSE, legend_title = "Inequity Aversion", vline = 0) + 
  facet_grid(rows = vars(feature), cols = vars(dataset), scales = "free_y", space = "free_y", labeller = function(x) label_value(x, multi_line = FALSE)) +
  theme(strip.text.x = element_text(size = 8),
        strip.text.y = element_text(size = 5))
@

\clearpage

\section{Teele et al. (2018) Candidate Experiment}

\subsection{Replication using AMCEs}

<<tkr_amce_appendix, dependson=c("data_tkr"), fig.height=5, fig.width=8>>=
plot(
  cj(
   tkr, 
   winner ~ feature_sex + feature_experience + feature_marital + feature_job + feature_children + feature_age,
   id = ~ responseid,
   estimate = "amce"
  ),
)
@

\clearpage

<<tkr_amce_table, dependson=c("data_tkr"), results="asis">>=
print(xtable::xtable(
  cj(
   tkr, 
   winner ~ feature_sex + feature_experience + feature_marital + feature_job + feature_children + feature_age,
   id = ~ responseid,
   estimate = "amce"
  )[c("feature", "level", "estimate", "std.error", "z")],
  digits = 2, align = c("l", "l", "p{1.5in}", "r", "r", "r")
), include.rownames = FALSE)
@

\clearpage

\subsection{Replication using MMs}

<<tkr_mm_appendix, dependson=c("data_tkr"), fig.height=5, fig.width=8>>=
plot(
  cj(
   tkr, 
   winner ~ feature_sex + feature_experience + feature_marital + feature_job + feature_children + feature_age,
   id = ~ responseid,
   estimate = "mm",
   h0 = 0.5
  ), vline = 0.5
)
@

\clearpage

<<tkr_mm_table, dependson=c("data_tkr"), results="asis">>=
print(xtable::xtable(
  cj(
   tkr, 
   winner ~ feature_sex + feature_experience + feature_marital + feature_job + feature_children + feature_age,
   id = ~ responseid,
   estimate = "mm",
   h0 = 0.5
  )[c("feature", "level", "estimate", "std.error", "z")],
  digits = 2, align = c("l", "l", "p{1.5in}", "r", "r", "r")
), include.rownames = FALSE)
@

\clearpage

\subsection{Subgroup Analysis for Teele et al. (2018) Candidate Experiment using AMCEs}

<<tkr_subgroup_amce_appendix, dependson=c("data_tkr"), fig.height=5, fig.width=8>>=
plot(
  cj(
   subset(tkr, !is.na(PartyID)), 
   winner ~ feature_sex + feature_experience + feature_marital + feature_job + feature_children + feature_age,
   id = ~ responseid,
   estimate = "amce",
   by = ~ PartyID
  ), group = "PartyID"
)
@

\subsection{Subgroup Analysis for Teele et al. (2018) Candidate Experiment using MMs}

<<tkr_subgroup_mm_appendix, dependson=c("data_tkr"), fig.height=5, fig.width=8>>=
plot(
  cj(
   subset(tkr, !is.na(PartyID)), 
   winner ~ feature_sex + feature_experience + feature_marital + feature_job + feature_children + feature_age,
   id = ~ responseid,
   estimate = "mm",
   by = ~ PartyID,
   h0 = 0.5
  ), vline = 0.5, group = "PartyID"
)
@

\clearpage

\subsection{Comparison of Alternative Reference Categories for Teele et al. (2018) Candidate Experiment}

<<tkr_subgroup_example, dependson=c("data_tkr")>>=
# estimates benchmarked to largest difference between subgroups
tkr.A <- tkr
    tkr.A$feature_sex <- relevel(tkr.A$feature_sex, "Male")
    tkr.A$feature_experience <- relevel(tkr.A$feature_experience, "None")
    tkr.A$feature_marital <- relevel(tkr.A$feature_marital, "Doctor Spouse")
    tkr.A$feature_job <- relevel(tkr.A$feature_job, "Corporate Lawyer")
    tkr.A$feature_children <- relevel(tkr.A$feature_children, "1 child")
    tkr.A$feature_age <- relevel(tkr.A$feature_age, "65")
# estimates benchmarked to smallest difference between subgroups
tkr.B <- tkr
    tkr.B$feature_sex <- relevel(tkr.B$feature_sex, "Male")
    tkr.B$feature_experience <- relevel(tkr.B$feature_experience, "1 year")
    tkr.B$feature_marital <- relevel(tkr.B$feature_marital, "Farmer Spouse")
    tkr.B$feature_job <- relevel(tkr.B$feature_job, "Mayor")
    tkr.B$feature_children <- relevel(tkr.B$feature_children, "No children")
    tkr.B$feature_age <- relevel(tkr.B$feature_age, "45")
# formula
f1 <- winner ~ feature_sex + feature_experience + feature_marital + feature_job + feature_children + feature_age
# estimate
amce_by_pid_1 <- cj(subset(tkr.A, !is.na(PartyID)), f1, id = ~ responseid, estimate = "amce", by = ~ PartyID)
amce_by_pid_2 <- cj(subset(tkr.B, !is.na(PartyID)), f1, id = ~ responseid, estimate = "amce", by = ~ PartyID)
# tag datasets and merge
amce_by_pid_1$dataset <- "A"
amce_by_pid_2$dataset <- "B"
amce_ref_tkr_merged <- rbind(amce_by_pid_1, amce_by_pid_2)
amce_ref_tkr_merged$level <- factor(amce_ref_tkr_merged$level, levels = with(tkr, c(levels(feature_sex), levels(feature_experience), levels(feature_marital), levels(feature_job), levels(feature_children), levels(feature_age))))
@


<<tkr_subgroup_example_plot, dependson=c("data_tkr", "tkr_subgroup_example"), fig.width=10, fig.height=10, fig.caption="Alternative Reference Categories Features in Teele et al. (2018) Candidate Experiment">>=
plot(amce_ref_tkr_merged, group = "PartyID", feature_headers = FALSE, legend_title = "Party Identification", vline = 0) + 
  facet_grid(rows = vars(feature), cols = vars(dataset), scales = "free_y", space = "free_y", labeller = function(x) label_value(x, multi_line = FALSE)) +
  theme(strip.text.x = element_text(size = 8),
        strip.text.y = element_text(size = 5))
@


\clearpage

\section*{}

\noindent This paper was built using \texttt{knitr::knit2pdf()} under the following environment:

<<session_info, cache=FALSE>>=
sessionInfo()
@

\end{document}
